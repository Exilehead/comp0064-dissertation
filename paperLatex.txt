\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{todonotes}
\usepackage[%  
    colorlinks=true,
    pdfborder={0 0 0},
    linkcolor=blue
]{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{codingstyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=codingstyle}
\newcommand\alberto[1]{\todo[color=yellow,inline]{\textbf{Alberto: }{#1}}}
\newcommand\firstpassrevision[1]{\todo[color=yellow,inline]{\textbf{First Pass Revision: }{#1}}}

\title{A Blockchain Attack Detector against new types of Safety Attacks' attempts on HotStuff}
\author{\\Anonymous Author due to submission requirements }
\date{\\September 2022}
\begin{titlepage}
\maketitle{
\begin{center}University College London\end{center}\\\\\\
\begin{center}This report is submitted as part requirement for the MSc Degree in Information Security at University College London. It is substantially the result of my own work except where explicitly indicated
in the text. The report may be freely copied and distributed provided the source is explicitly acknowledged.\end{center}\\\\\\
\begin{center}Supervisor: Philipp Jovanovic, Alberto Sonnino\end{center}}\\\\\\
\begin{center}Candidate Number: QYWC5\end{center}

\end{titlepage}

\newpage
\thispagestyle{empty}
\mbox{}
\newpage


\begin{abstract}
HotStuff is a leader-based Byzantine Fault Tolerant(BFT) consensus protocol working on blockchains. It is reliable and secure against safety attacks like double-spending attacks with its mature defending mechanisms. However, the current HotStuff protocol does not have the functionality of detecting occurrences of those safety attacks. It is necessary to detect those occurrences too because developers want to blacklist malicious nodes to enforce a transaction environment maintaining information security as bottom-line insurance.\\\\
This paper will propose some new types of Byzantine behaviors in the form of attempting safety attacks. Then, an original detector written in Python will try to detect occurrences of those attempts of safety attacks by parsing generated logs from the simulation of transactions over transactions. Simulation of attacks is the method for experiments and additional logs will help the detector by providing more information too. This detector returns a close to perfect result detecting those safety attacks. However, detection over liveness attacks remains unsolvable.
\end{abstract}

\newpage
\thispagestyle{empty}
\mbox{}
\newpage


\begin{center}
\maketitle{Acknowledgement}
\begin{center}I would like to thank my supervisor Prof. Philipp Jovanovic and Dr. Alberto Sonnino for continuous work putting in guidance, suggestion, and verification for the completion of this dissertation. They conduct weekly meetings and constant emails conversations going throughout the whole project, which help guide the whole experiment and dissertation write-up in the correct direction with their responsible and tireless endeavors.\\\\
Also, special thanks to my family for backup support too. \end{center}
\end{center}

\newpage
\thispagestyle{empty}
\mbox{}
\newpage

\begin{document}

\tableofcontents

\newpage
\thispagestyle{empty}
\mbox{}
\newpage

\section{Introduction}\label{sec:1}
Blockchain has various applications, and the most prominent application is cryptocurrencies. Numerous people choose to trade in cryptocurrencies, because they trust that the blockchain can offer them high-standard security, with properties of tamper-resistance, pseudonymity, consistency, etc. [20]\\ \\
However, there're many types of safety attacks that can hurt the security of blockchain's consensus, causing destructive consequences like double-spending, which is one of the ultimate goals of safety attacks that blockchain developers must work to prevent.[21] Mcafee has defined double-spending as a severe technology attack that can spend one coin multiple times for different receivers. [11] \\ \\
Blockchain developers like HotStuff developers have committed huge efforts to defending against safety attacks. HotStuff is a leader-based Byzantine Fault Tolerant consensus protocol, and it is simple and efficient, which makes transactions flow without too many congestions.[4] More importantly, it is secure that mature technologies have been implemented on defending against safety attacks in its low-level code. And then, the attacker cannot carry out any safety attacks successfully.\\ \\
HotStuff does defend against safety attacks. However, \textbf{it does not detect the occurrence of any attempts of those safety attacks}. This paper will introduce ways how HotStuff can detect the occurrences of those attacks precisely.\\

\subsection{Motivation}\label{sec:1.1}
\textbf{One major challenge: how to find attackers attempting Byzantine behaviors and blacklist them:} Byzantine behaviors are safety or liveness attacks conducted by malicious nodes on the blockchain.[12] The goal of this paper is to introduce methods of detecting attempts of safety attacks as Byzantine behaviors and blacklist those attackers in HotStuff. It seems unnecessary to detect since those Byzantine behaviors for safety attacks are already been defended in the current HotStuff consensus. But \textbf{a major challenge in current BFT-based protocol is to find the attackers and blacklist them, which is what current BFT-based protocol's defense lacks}. A Byzantine behaviors detector can further protect HotStuff's safety and keep a moral transaction environment by finding attackers. Here're reasons why HotStuff developers should blacklist those attackers:\\\\
\textbf{Locate problems on the failed transaction: }Transactions sometimes can fail. Many factors can cause this phenomenon, like if there're many dead nodes, voting message loss, liveness attacks, or if there's a safety attack that has been already blocked by consensus. When all nodes find transaction failure, they won't know what happens and will spend extra time locating the problems, which is a huge performance overhead. So, if the failure is caused by safety attacks, honest nodes will know that there're malicious nodes performing safety attacks and can resume the transactions fastly by blacklisting the malicious nodes.\\\\
\textbf{Honest nodes know who are malicious: }Additionally, if honest nodes know who are malicious nodes, then they will not do any transactions with those malicious nodes. That can protect them from the risks of suffering safety attacks from those malicious nodes.\\\\
\textbf{Maintain incentive: }To promote a secure transaction environment, HotStuff consensus always asks all nodes to pay the deposit. That is if nodes are attempting Byzantine behaviors, then their deposit will be confiscated by HotStuff, which makes malicious nodes think twice if is it worth being Byzantine. That is a downside when attempting safety attacks, and honest nodes will not be tempted to become corrupted. Thus, node operators are encouraged to be honest throughout every transaction and help build an environment putting information security as the supreme goal.

\subsection{Contributions}\label{sec:1.2}\\
This paper focuses on detecting safety attacks and blacklist attackers. Thus, new ideas as contributions presented are:\\\\
\textbf{New types of attempts of safety attacks on HotStuff: }Section \ref{sec:4} presents many new Byzantine behaviors from both leaders and replicas that they want to use to conduct safety attacks, other than existing attacks like those in Section \ref{sec:3}. By modifying Alberto Sonnino's implementation of Two-chained Hotstuff code in https://github.com/asonnino/hotstuff with commit hash of e115fa2e4fd1ddfd42e757c3abaec331b9b9fffb, Byzantine behaviors in section \ref{sec:4} can be simulated.\\\\
\textbf{A Detector as a Python script: }Like other attempts of safety attacks, attacks in section \ref{sec:4} can be defended by the current HotStuff protocol, causing related transactions to fail. However, those failed transactions cannot tell any further information. Thus, section \ref{sec:5} and \ref{sec:6} present detection methods over attacks in section \ref{sec:4} by modifying generation of logs by simulation of attacks. Those culminated in Python scripts. The code can be accessed at https://github.com/Exilehead/comp0064-dissertation. \\
\subsection{Outline}\label{sec:1.3}
This paper flows as follows: Section \ref{sec:2} gives out background information on HotStuf and a comparison of Safety attacks and other abnormal situations. Section \ref{sec:3} discusses related work focusing on existing Byzantine Behaviors on HotStuff and detections in other protocols. Section \ref{sec:4} introduces types of potential attempts of safety attacks that malicious nodes can execute on HotStuff. Section \ref{sec:5} reinforces the meaningfulness of blockchain attack detectors and discusses detection methods in a high-level description. Section \ref{sec:6} will briefly discuss the low-level implementation of the detecting experiment and results analysis. Section \ref{sec:7} will discusses limitation. Section \ref{sec:8} will wrap up and point out some directions for future work.

\section{Background}\label{sec:2}
This section will give a more detailed view of understanding the experiments in later sections. Section \ref{sec:2.1} introduces HotStuff by introducing an overview of its consensus protocol. Then this subsection will show HotStuff's protocol's special properties. Section \ref{sec:2.2} will conduct a comparison study on Safety attacks, Liveness attacks, and Accidental Behaviors since liveness attacks and Accidental behaviors can impact detections over safety attacks.
\subsection{HotStuff}\label{sec:2.1}
\subsubsection{Leader-based BFT consensus protocols}\label{sec:2.1.1}
\textbf{Byzantine General Problems: }HotStuff implements the Leader-based Byzantine Fault Tolerant consensus protocol. The idea of this protocol originated from an old problem that is Byzantine Generals problem existing in the P2P network.[1] That is when many generals distributed in different places are aiming to attack the enemies, there might be traitors there deluding all generals into attacking other innocent people (violating safety) or making all generals into a chaotic state of not performing any attacks (violating liveness).[1] This applies to P2P networks too, that are safety attacks and liveness attacks existing in it. The takeaway for leader-based BFT from that problem is knowing how to achieve both safety and liveness. 
Leader-based Byzantine Fault Tolerant (BFT) consensus protocol is one solution to the Byzantine problem in the blockchain. Generally, leader-based BFT is using view synchronization in that one leader is rotating randomly for each view (round), and the leader for each round will generate a proposal of accepting the incoming transaction to other replicas. [13] Other replicas will decide on whether they pass this proposal. Then, they will send the voting messages to the leader to tell whether they agree with that proposal or not. There can be at most f fault nodes. If 2f + 1 of replicas agree, then that transaction can flow into the next stage. BFT-based protocols like HotStuff, Diem [14], Celo [15], etc. all have varied consensus algorithms on implementations. Thus, this promote the safety and liveness as the solution to Byzantine general problems. The reason for not setting a threshold of all(1) or nothing(0) is that they are not the most optimal solutions due to network model reasons. [16]\\\\
\subsubsection{BFT's node identity management}\label{sec:2.1.2}
Nakamoto consensus is the most famous consensus protocol used for cryptocurrencies like Bitcoin. Bitcoin uses Proof of Work(PoW) to select nodes who participate in the Nakamoto consensus protocol. Vukolic conducted a comparison study on PoW vs BFT [2]. Figure \ref{fig:vukolic1} shows their differences in his paper. The one that helps understand the works below is node identity management. Normal consensus like PoW is decentralized, which means the node can choose not to reveal its identity to others. But BFT forces permissioned and centralized identity management that nodes must know the IDs of others. Thus, if one node is Byzantine and blacklisted by my detector, then other nodes will know who is that node by checking with its public key. Thus, BFT's permissioned identity management helps to blacklist easier, though taking more performance costs on verifying the identities of nodes. [22]\\
\begin{figure}[t]
  \centering
  \includegraphics[scale=0.5]{f1.PNG}
  \caption{Vukolic's comparison on PoW vs BFT. [2]}
  \label{fig:vukolic1}
\end{figure}
\subsubsection{Leader-based BFT's variant: HotStuff}\label{sec:2.1.3}
HotStuff is the leader-based BFT replication protocol for the partially synchronous model. [4, 25] It defines the threshold agreement a little differently than the traditional BFT consensus that there're  $ 3f + 1$ nodes and if there're f Byzantine(malicious) nodes, then there must be at least $ 2f + 1 $ non-faulty nodes presented to make a QC.[4] QC, quorum certificate, works like a signature proving the integrity of the agreement and is binded with the proposal. The QC must be formed with $ 2f + 1 $ votes agreeing on one proposal.\\\\
HotStuff itself has many variants too. This section introduces the basic HotStuff.\\\\
\textbf{Basic HotStuff [4]: }Basic Hotstuff implements view synchronization method as section \ref{sec:2.1} states. In contrast with traditional BFT-based consensus, there're four phases of one transaction flow: Prepare, Pre-commit, Commit, and Decide. \\\\In Prepare phase, the leader for each view selects the branch from the blockchain with the highest view number to form a prepareQC. The leader then extends the last node on that branch with a new proposal. Then replicas will use the safeNode predicate to verify with the safety and liveness rule to ensure that proposal can be approved without violations. If the replica approves, it will send the voting message back to the leader. When the leader has gathered $2f+1$ of votes, it will initiate the Pre-commit phase. [4]\\\\
Then in the Pre-commit phase, the leader combine votes gathered from those replicas into PrepareQC. Then the leader broadcasts the prepareQC to all replicas. Replicas verify the prepareQC and send the Pre-commit votes back to the leader. [4]\\\\
After the leader receives 2f+1 Pre-commit votes, it starts the Commit phase. This phase is similar to Pre-commit phase, except that the leader combines votes and sends a PrecommitQC to replicas. Moreover, the replica is locked on the precommitQC so it cannot commit any proposals at this stage. This protects the safety of the proposal to prevent the proposal from being committed now and becoming the consensus decision. The replicas must send a Commit voting message back to the leader. [4]\\\\
Now in the last phase, the Decide phase, the leader assembles those votes into a commitQC, and sends them to all replicas. Now replicas can execute commands to commit the proposal, increment the view number, and goes into the next round of transaction. [4]\\\\
There are also specifications of data structures in the HotStuff paper[4]:\\\\
First, messages are formed of type, representing which stage is now. It also embeds the current view number with which node to extend. \\\\
Then, QC is combining many signatures signed by 2f+1 replicas. QC is carried with the message. When two messages are with the same view number, nodes, and types, if they carry different QCs, then they are different messages. \\\\
After knowing the phases and data structures of basic HotStuff, now it's worth knowing its algorithms of how the whole transaction goes. Following are algorithms on the HotStuff paper:\\\\
In Figure \ref{fig:hotstuff1} that is the utility of forming messages, QC, voting message, justifying whether message/QC is matched, and safeNode predicate functions checking safety/liveness rule.\\\\

\begin{figure}
  \includegraphics[scale=1.1]{f2.PNG}
  \caption{Basic Hotstuff's Utility function.}
  \label{fig:hotstuff1}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{f3.PNG}
  \caption{Basic Hotstuff's protocol algorithm.}
  \label{fig:hotstuff2}
\end{figure}
Figure \ref{fig:hotstuff2} introduces specific implementations in each phases. Generally, it is the interaction between the leader and replicas introduced above in each phase.\\\\
The HotStuff codebase I use for this project is implementing two-chained HotStuff. The key difference between Basic and Two-chained is that all four phases in basic HotStuff are simplified into one phase, which is efficient. Figure \ref{fig:hotstuff3} shows the chained HotStuff's general algorithm.
\begin{figure}
  \includegraphics[scale=1.2]{f4.PNG}
  \caption{Chained Hotstuff's protocol algorithm.}
  \label{fig:hotstuff3}
\end{figure}
\subsection{Safety Attacks VS Liveness Attacks VS Accidental Behaviors}\label{sec:2.2}
The blockchain attack detector in this paper is for attempts of safety attacks. Thus, another key background information that helps readers understand the following sections is the concepts of Safety attacks, Liveness attacks, and Accidental behaviors. Furthermore, it is crucial to know the differences between them.
\subsubsection{Overview}\label{sec:2.2.1}
\textbf{Safety attacks: }Safety means people can expect that results are desirable. [5] Thus, safety attacks mean attacks that lead to undesired effects. In HotStuff, there're many attempts of safety attacks, like all safety attacks described in Twins paper that will be further discussed in Section \ref{sec:3} [6]. All these safety attacks try to cause undesirable effects like double-spending. Also, the consistency promise will be broken, since the total order of transactions on each node is not guaranteed to be the same anymore. [24]\\\\
\textbf{Liveness attacks: } Liveness means people can expect that results are coming out eventually without congestion or loss. Thus, liveness attacks mean attacks that lead to delay or loss of a system's desirable effects.[5] In the blockchain, Liveness attacks will cause transactions to flow very slowly or just be lost. For example, a DDoS attack is a type of liveness attack on Blockchain that the unrelated messages will be continuously sent to all nodes, and the transaction message will always arrive later than those unrelated messages, causing transactions cannot be further conducted. There's a countermeasure of deterring DDoS by optimizing mempool size and reducing effects from DDoS, but cannot fully defend against it.[19] Thus, the overall performance is the biggest victim with such a slow transaction or loss of transactions. \\\\
\textbf{Accidental behaviors: }Accidental behaviors are common accidental stuff happening on Blockchain, like a bad network causing extremly slow transactions. This is is caused by unpredictable events. Network reliability is one key property causing Accidental behaviors on Blockchain. When one message is sent from the leader to a replica in HotStuff, there can be message loss if the network connection is interrupted. Then, the replicas will not receive this message. HotStuff does have a resending mechanism for messages to be resent, but that still hurts the performance of that additional time duration of message loss.
\subsubsection{Compare and Contrast}\label{sec:2.2.2}
These three behaviors are easy to be confused with each other. Here're some contrasts telling their differences:\\\\
\textbf{Intention: }Safety attacks and liveness attacks are all initiated by human factors since there must be adversaries to conduct those attacks. But Accidental behaviors are always unintentional non-human factors like network stability, node machine's halt, concurrency issues, etc.\\\\
\textbf{Consequences: } Safety attacks are always leading to unexpected effects on the blockchain. More specifically, there will be an inconsistent view of the blockchain state agreeing on which transactions take place in which order. [7] Double-spending is not consistent because the expected result is there's only one receiver getting the transferred money, while two receivers getting the transferred money. In contrast, liveness attacks and Accidental behaviors both lead to delay or loss of transactions. That is the blockchain's state is slowly or never updated.[7] If the result comes out, it's always the expected result, unlike safety attacks. But these results are always delayed, or there's doubt existed that actually, all nodes will not see this result due to message loss, whether intentionally due to liveness attacks or unintentionally due to Accidental behaviors.\\\\
\textbf{Security: }Safety attacks can lead to huge security threats to blockchain's security, while liveness attacks and Accidental behaviors cannot. Imaging there're safety attacks that redirect people's money to other accounts, and there're liveness attacks or Accidental behaviors that just make people's transactions fail while still holding that money, obviously, safety attacks are causing much more security threats due to the extent of severity of losing money over failed transactions.\\\\
\textbf{Performance: }In contrast with security, liveness attacks and Accidental behaviors will lead to bad performance compared with safety attacks. Liveness attacks aim to delay transactions or cause transaction loss, while Accidental behaviors are causing same effects too. That will waste a long time for a transaction, and that is bad performance. Adversaries doing safety attacks always aim to steal coins as fast as possible, to give less time to the overall blockchain system to detect or defend against such behaviors. Thus bad performance is only applied to liveness attacks and Accidental behaviors.\\\\
\textbf{Differentiation and Difficulty of Detection: } The most important properties worth discussing in this paper are Differentiation and Difficulty of Detection because that is the most crucial reason this paper just put focuses on detecting attempts of safety attacks. Safety attacks are easy to differentiate from all malicious behaviors because when people see unexpected outcomes like double-spending, redirected money, etc., that is caused by safety attacks. Thus that eases detection to capture those misbehaved nodes. In contrast, when people see delayed transactions or message loss, they will not have $100\%$ of confidence to point out that those are caused by liveness attacks or Accidental behaviors. Because liveness attacks and Accidental behaviors are yielding the same consequences, both are hard to be differentiated from each other. For instance, Tangaroa[23], an extension of a consensus algorithm tolerating Byzantine behaviors, does not have a verification method over a liveness attack. When a malicious node refuses to become the leader for one round and is "dead", then there's no transaction in this round. [23] However, the accidental behavior of network instability can cause the same results by delay or loss of transactions from honest nodes. Thus, the malicious node doing liveness attacks actively and the honest node suffering from accidental behaviors passively are showing the same behaviors to other honest nodes: Leaders are not proposing anything, but honest nodes don't know whether caused by liveness attacks or accidental behaviors. [23] Thus, this is a limitation for blockchain attack detectors nowadays and will be further discussed in Section \ref{sec:7} and \ref{sec:8}.
\section{Related Work}\label{sec:3}
Since this paper is discovering new types of attempts of safety attacks on HotStuff and their detections, the related work section presents current work on finding safety attacks with respective defenses against them. This paper plans to complement the area of safety attacks defense in BFT-based consensus by finding specific detections technique on HotStuff to blacklist those attackers. One paper about Twins from Shehar Bano et al. is chosen to discuss for literature review.
Twins[6] is an automated unit test generator of Byzantine attacks. Twins paper proposed general ideas and specific algorithms of safety/liveness attacks, simulated them with Twins, and detected them. Two general ideas of Byzantine behaviors are Equivocation and Amnesia. In addition, some detection mechanisms over Ethereum [31] will be introduced too, showing current work is limited to blockchains other than BFT-based blockchain and is just safety attacks. 
\subsection{Equivocation }\label{sec:3.1}One typical Byzantine behavior is equivocation. [6] Within one round, the malicious leader can attempt to propose multiple different proposals, and send each of them to different replicas. That is Byzantine behavior because the leader is only permitted to either just send one message within one round, or resend the same messages within one round if there are Accidental message losses or dead replicas. Thus, if the BFT consensus protocol is free of a defense mechanism on message numbers and content checks when different messages are replayed to different recipients, then there will be two different proposals committed later, causing potential double-spending by having both P1 and P2 committed within one round.\\
\begin{figure}
    \centering
  \includegraphics[scale=0.6]{f5.PNG}
  \caption{a toy example of equivocation}
  \label{fig:hotstuff4}
\end{figure}
\begin{figure}
\centering
  \includegraphics[scale=0.6]{f6.PNG}
  \caption{a toy example of Amnesia}
  \label{fig:hotstuff5}
\end{figure}
Here's an example: In Figure \ref{fig:hotstuff4}, there's 4 nodes. Black circles represent Byzantine nodes, while White circles represent honest nodes. The leader is malicious, and in one round, it proposes proposals P1 and P2. P1 and P2 are with different messages, which is prohibited. In normal BFT consensus, honest nodes R1 and R3 only vote for one proposal within one round. Thus, the leader partitions 4 nodes into two groups: G1: ${Leader, R2, R1}$ and G2: ${Leader, R2, R3}$. The leader sends P1 to G1 and P2 to G2. Now honest node R1 only sees P1 in this round and will vote for P1, while R3 only sees P2 in this round and will vote for P2. Two malicious nodes will vote for both proposals. Thus, if there're f nodes, total nodes must be 3f+1 to tolerate fault. Since 3f+1=4, f is 1. And in this scenario, there are 2 fault nodes, which are f+1. That means the safety guarantee is broken. And since one quorum needs 2f + 1 votes, that means 3 votes are sufficient to pass one proposal. And since G1 all passes P1 and G2 all pass P2 and $|G1| = |G2| = 3$, two proposals are both passed and can be committed in the later stage. \\\\
Thus, Twins paper mentioned that there must be a defense mechanism presented in all BFT-based consensus to prevent from one leader proposing multiple different proposals within one round, and this paper's work in Section \ref{sec:4.1.1} and \ref{sec:5.2.1} does elaborate on this idea to propose one detection mechanism over a similar situation of attacks.
\subsection{Amnesia }\label{sec:3.2}Amnesia [6] is more of malicious voters' behavior. That is when one proposal is sent from the leader, the voter sends back the voting message, pretends to be an amnesiac, and sends another voting message again. Malicious voters intend to vote twice for one proposal for it to be passed.\\

Here's an example: Like in the Equivocation example, in Figure \ref{fig:hotstuff5}, there're two Byzantine nodes including the malicious leader and two honest nodes. This time within one round, the leader sends P1 to all of the nodes. After all nodes vote for P1, it sends P2 to all nodes. Now honest nodes R1 and R3 reject P2 because they have already voted for one proposal within this round, and will not vote for other different proposals now. Only the leader and R2 vote for P2, and there're only 2 votes now. There must be 3 votes to pass P2. So, R2 will choose to vote twice by sending another vote to the leader for P2, and P2 now has 3 votes, and P2 will be passed and committed later, still can cause double-spending by having both P1 and P2 committed within one round.\\\\
Thus, there must be a defense mechanism in all BFT-based blockchains that mandate voters' behaviors. All votes must only vote once within one round. This paper's work in Section \ref{sec:4.2} and \ref{sec:5.3.1} does elaborate on this idea to propose one detection mechanism for a similar situation of attacks from voters.
\subsection{Current work on detections for Ethereum} Researchers are indeed working on detections over safety attacks over other consensus protocols like Ethereum. For instance, Scicchitano et al. conducted detections over the 51 percent attack [30] and DAO[32] attacks on Ethereum with a deep learning method called the recurrent autoencoder (RAE) model.[27] That is to generate sequences of trends of events to be wave graphs and do some input and output comparisons to check if is there any inconsistent waves in the graphs.[27] If there is, then an attack happens in the transactions. In addition, Ramanan et al. conducted another research on detections over replay attacks [29] with Bayesian update mechanism and culminated into scatter plot graphs to identify attacks there. The common thing is both detections are all over (1) safety attacks and (2) Ethereum.[28] However, there's very little work conducting detections over liveness attacks, or on BFT-based blockchains. Detection over attacks on Ethereum is easier because Ethereum is a synchronized blockchain with mature defense and detection over attacks, while BFT-based blockchains are partially synchronized and have little work on detections over attacks. So, this paper will try to do one of the lacking points which is detection on BFT-based blockchains. 

\section{New types of attempts of Safety attacks on HotStuff}\label{sec:4}
As previous sections point out, all Byzantine behaviors in section \ref{sec:3} and this section are attempts of safety attacks, which mean they are unsuccessful in the current BFT-based consensus unless unexpected security flaws are occurring in the consensus, because the current BFT-based consensus is mature in defense against safety attacks. But there're no known safety attacks that can exploit current BFT-based consensus like HotStuff.\\
However, the current HotStuff protocol only concerns defenses, ignoring detections of such Byzantine behaviors. This section is closely related to section \ref{sec:3} that proposes attempts of safety attacks as variants of Equivocation and Amnesia, with one category of completely new attacks. Section \ref{sec:4.1.1} introduces one variant of Equivocation called \textbf{Attack 1}, section \ref{sec:4.1.2} introduces new attacks called \textbf{Attack 2.1 and 2.2}, and section \ref{sec:4.2} introduces variants of Amnesia called \textbf{Attack 3, 4.1, and 4.2}. Moreover, liveness attacks \textbf{"Attack 1"} and \textbf{"Attack 2"} are also discussed in section \ref{sec:4.1.3} for interference purposes in the implementation of the detector.
\subsection{Malicious Leader}\label{sec:4.1}
Let's start with Byzantine behaviors from malicious leaders. In HotStuff, leaders' main responsibility is broadcasting voting messages to replicas, and calculating the votes it receives from those replicas. If votes have reached the threshold value 2f+1, then transactions can be approved. We use two-chained HotStuff as a case study for simplification reasons.  
\subsubsection{Multiple different proposals within one round}\label{sec:4.1.1}
Equivocation is there're two different proposals within one round, and the leader will partition all nodes into two groups, and send one proposal to one group while sending the other proposal to the other group. \\\\
\textbf{Attack 1:} The new variant of equivocation is omitting the partition step. Instead, the leader broadcast two proposals to all nodes within one round directly. In the later section, this attack is abbreviated as Attack 1. As Figure \ref{fig:hotstuff7} shows, compared with Figure \ref{fig:hotstuff4}, this time proposals P1 and P2 are both sent to all nodes, instead of two subsets of nodes. And inevitably, R1 and R3, the honest nodes, will reject P2 since they have already seen P1 within this round. This attempt of a safety attack is an edged-case variant of Equivocation.\\\\
Attack 1 is attempting a safety attack like equivocation, because the leader still wants to cause double-spending by having different QCs in P1 and P2, leading to messages carrying different proposals. QC serves many purposes. One purpose is it indicates where the node on the HotStuff blockchain will be the leaf to be branched to create a new node for the current transaction. If QC in P1 says it wants a new transaction to be branched from node 10, and the QC in P2 says it wants a new transaction to be branched from node 9, then if HotStuff has a security flaw and both P1 and P2 are committed in this round, then malicious fork occurs. Now at both nodes 9 and 10, the transactions are placed and branched from the blockchain as in figure \ref{fig:hotstuff8}, which is typical double-spending. \\\\
In formulation form, let's assume for two proposals P1 and P2, if they are carrying round numbers R1 and R2, QC QC1 and QC2, then it is Attack 1 if:\\\\
\[R1 = R2; QC1 \neq QC2\]\\
That means within the same round, P1 and P2 are with different QCs.\\

\begin{figure}
\centering
  \includegraphics[scale=0.6]{f7.PNG}
  \caption{a toy example of Attack 1}
  \label{fig:hotstuff7}
\end{figure}
\begin{figure}
  \includegraphics[width=\linewidth]{f8.PNG}
  \caption{HotStuff with defense against double-spending vs no defense}
  \label{fig:hotstuff8}
\end{figure}
\begin{figure}
\centering
  \includegraphics[scale=0.6]{f9.PNG}
  \caption{If the node is successfully committed to be branched from previous nodes, the left chain is forfeited, and new transactions are always on the right chain, causing double spending and redirection of money}
  \label{fig:hotstuff9}
\end{figure}
\subsubsection{Proposal with non-consecutive round number: Two variants}\label{sec:4.1.2}
The next attempts of attacks are completely new types of Byzantine behaviors for safety attacks, which are not variants of existing Byzantine behaviors attempting safety attacks. Imagine one scenario where the malicious leader wants to branch from a previous node instead of the current node as Attack 1 does, the intention of it is still for double-spending. But this time this malicious leader wants to achieve more damage by creating a fork in previous nodes and forfeiting all original branch's nodes that are committed after previous nodes. Figure \ref{fig:hotstuff9} illustrates this scenario. That causes huge harm that all new transactions will be branched from node 12, and goes way down, and all nodes after node 12 will be controlled by the malicious party. Thus double spending or redirection of coins can occur. \\
HotStuff's round number is monotonically increasing. Each round is in consecutive order. To conduct attacks in this subsection, the malicious leader must propose a proposal with a non-consecutive round number with the previous one. For example, if the leader proposes at round 10, then becomes a replica at rounds 11, and 12. Later, that leader re-becomes the leader at round 13. But that leader will not propose a proposal with round number 13. Instead, it will propose with round number 12, or 11, or 14, etc. With non-consecutive round numbers, the block can be made not in current nodes. There're 4 scenarios as variants, with two of them as attempts of safety attacks, while the other two are liveness attacks in section \ref{sec:4.1.3}. This section introduces those two attempts of safety attacks as Attack 2.1 and Attack 2.2:\\

\textbf{Attack 2.1: }Leader making proposals with non-consecutive round number R, and R is smaller than a current round number, and in previous round R it was the leader, and the message in the current round is different from in round R. \\\\
Using Figure \ref{fig:hotstuff10} as an example, for the left Attack 2.1, the red node means it is the leader in that round with the number indicated above, while the white node means it is a replica. The upper node is always the malicious one, while the lower node is always the honest one. \\\\
The leader is making proposals at round 10 with QC of 9, then becomes replica in round 11, 12, then re-become leader at round 13 but proposes proposal with round number 10 with different messages from the proposal in round 10, that is with QC of 8 not equal to 9. \\\\
To formulize it, Let's say there're 2 proposals Pa and Pb with Pb as the proposal proposed later than Pa, both carrying with round number Ra and Rb, QC of QCa and QCb, proposed leader La and Lb, and let's set current round to be Rc. Then if:\\\\
\[Ra = Rb; QCa \neq QCb; Rb < Rc; QCb < Rc; La = Lb;\]\\
Then the scenario satisfies Attack 2.1.\\\\
To argue why this attack is an attempt of a safety attack instead of a liveness attack, just look at the above conditions one by one. Since Rb is not equal to Ra, that means this leader is proposing a proposal with a non-matching round number with the current round Rc. And QCa does not equal to QCb means these two proposals are carrying different messages. Thus, this eliminates the possibility of Accidental behaviors of losing messages and resending again mechanism from that leader, because if resend the proposal, then the proposal must be the same as the lost proposal. And QCb must indicate that it will be branched from a committed node, which should be less than Rc because the HotStuff consensus ban from committing any node bigger than the current round number. If branched from an uncommitted node, that is a liveness attack which is discussed as another variant in section \ref{sec:4.1.3}. But since it attempts to be branched from a committed node, that's the intention of safety attacks by double-spending. Leaders should be the same to achieve safety attack 2.1 because the same leader cannot propose different proposals with the same round number. Leaders can be different, but then the above condition is a subset of Attack 2.2, which is introduced below:\\\\
\textbf{Attack 2.2: }Leader making proposals with non-consecutive round number R, and R is smaller than a current round number, and in previous round R it was a replica, regardless of same or different messages.\\\\
Still using figure \ref{fig:hotstuff10} as an example, the above malicious leader making proposals at round 10, becomes a replica in round 11, 12, then re-become leader at round 13 but proposes proposal with round number 11. That is Byzantine behavior too.\\\\
To formulize it, Let's say there're 2 proposals Pa and Pb with Pb as the proposal proposed later than Pa, both carrying with round number Ra and Rb, proposed leader La and Lb, and let's set the current round to be Rc. Then if:\\\\
\[Ra = Rb; Rb < Rc; QCb < Rc; La \neq Lb;\]\\
Then the scenario satisfies Attack 2.2.\\\\
To argue why this attack is an attempt of a safety attack instead of a liveness attack, we still need to look at the above conditions one by one. The above conditions are similar to conditions shown in Attack 2.1, except that leaders are different for the two proposals, and there's no QC check anymore. That is if two proposals with the same round number, and if the honest node committed that proposal before, and then the malicious node attempts to commit the other proposal later with the same round number, that is a safety violation too. Because the malicious leader was not the leader at Ra, and then as a leader proposes a proposal still with Ra, that is impossible to happen in the current HotStuff protocol. That is attempt of a safety violation, which doesn't need any verification over QCs.\\\\
Attack 2.1 and 2.2 are both Byzantine behaviors of attempting safety attacks. There are two very similar variants, but they are liveness attacks. And the below section \ref{sec:4.1.3} will argue why they are liveness attacks and the reason I introduce them in a paper focusing on safety attacks.\\
\begin{figure}
  \includegraphics[width=\linewidth]{f10.PNG}
  \caption{Attack 2.1 and 2.2}
  \label{fig:hotstuff10}
\end{figure}
\subsubsection{Variants of Byzantine behaviors in 4.1.2 as Liveness attacks }\label{sec:4.1.3}
\textbf{Purpose: Adding one realistic situation as interference for the detector:} This paper is aiming for detections over attempts of safety attacks, but this section introduces two variants of Attacks 2.1 and 2.2 as liveness attacks. The reason liveness attacks are discussed in this paper focusing on safety attack detection is for concerns over the realistic situation. The Byzantine nodes will not only conduct safety attacks. They have chances to conduct liveness attacks too. Then, if the detector is not robust and accurate, liveness attacks can make detection over safety attacks inaccurately. Like if there's no check on whether the current round number is bigger than the malicious proposal's round number or not, then "Attack 2" will be wrongly interpreted as a safety attack. Thus, a detector not only for the most ideal situation must be here.
\\\\
Attacks 2.1 and 2.2 are argued to be Byzantine behaviors of attempting safety attacks. Two similar scenarios are actually for liveness attacks or can be Accidental behaviors sometimes, and here're descriptions and brief arguments on why they are liveness attacks or just Accidental behaviors:\\\\
\textbf{"Attack 1": }Leader making proposals with non-consecutive round number R, and R is smaller than the current round number, and in previous round R it was the leader, and the message in the current round is same from in round R. For example, the malicious Leader making proposals at round 10, becomes replica in round 11, 12, then re-become leader at round 13 but proposes proposal with round number 10 with same messages from the proposal in round 10.\\\\
To formulize it, Let's say there're 2 proposals Pa and Pb with Pb as the proposal proposed later than Pa, both carrying with round number Ra and Rb, QC of QCa and QCb, proposed leader La and Lb, and let's set current round to be Rc. Then if:\\\\
\[Ra = Rb; QCa = QCb; Rb < Rc; La = Lb;\]\\\\
Then the scenario is NOT attempting for safety attacks.\\\\
To argue why it is not for safety attacks, let's do a comparison with this so-called "Attack 1" with Attack 2.1. The main difference is QC in the two proposals is the same. That means the two proposals are the same. That is a typical scenario that the later proposal can be interpreted as triggered by a resending mechanism due to Accidental behaviors, or are liveness attacks from the malicious leader for resending the same proposals again and again to delay or forfeit the whole transaction.\\\\
\textbf{"Attack 2": }Leader making proposals with non-consecutive round number R, and R is bigger than the current round number: Leader making proposals at round 10, becomes replica in round 11, 12, then re-become leader at round 13 but proposes proposal with round number 14.\\\\
This scenario was hinted at in Section \ref{sec:4.1.2}. To formulize it, Let's say there're 2 proposals Pa and Pb with Pb as the proposal proposed later than Pa, both carrying with round number Ra and Rb, and let's set the current round to be Rc. Then if:\\\\
\[Ra = Rb; Rb > Rc;\]\\\\
Then the scenario is NOT attempting for safety attacks.\\\\
This scenario is a typical liveness attack or Accidental behavior. The leader is proposing a proposal with an even bigger round number than the current round number, which means it is not attempting to branch from a committed node before. Instead, it is branched from an uncommitted node. That means there are no double spending attempts here because double spending must occur at the committed node to create a new branch to redirect the money. It is impossible to create such a branch on an uncommitted node. That can be liveness attacks if the attacker wants to send such proposals again and again to delay or forfeit the transactions, or just is Accidental behavior that the supposed proposal is lost, and the next proposal shown must be with a bigger round number because the round number is monotonically increasing.
\subsection{Malicious Voters}\label{sec:4.2}
After proposing malicious leaders' behaviors, let's see how malicious voters behave. They behave similar to Amnesia described in section \ref{sec:3} but is straightforward that all malicious voters voting for any Attack 1, Attack 2.1, and Attack 2.2 are showing Byzantine behaviors attempting safety attacks. Amnesia requires nodes to vote multiple times for one malicious proposal, but the following attacks are just of a sudden death behavior: if they vote for malicious proposals, then they are attempting Byzantine behaviors: \\\\
\textbf{Attack 3}: Any replicas voting for Attack 1 are attempting safety attacks.\\\\
\textbf{Attack 4.1}: Any replicas voting for Attack 2.1 are attempting safety attacks.\\\\
\textbf{Attack 4.2}: Any replicas voting for Attack 2.2 are attempting safety attacks.\\\\
To argue why they are attempting safety attacks, let's revisit Figure \ref{fig:hotstuff1}. In section \ref{sec:2.1.3} there's a safety and liveness rule check called safeNode predicate. That is for all replicas they need to check whether the incoming proposal is making node extended from lockedQC.node in Figure \ref{fig:hotstuff1}'s line 26. There's another idea in Twins paper called losing internal state. [6] That is some malicious nodes will not update their locked node state, which is lockedQC.node in this case, during some rounds, causing attempts of safety attacks by triggering safeNode predicate later. Here, malicious replicas can trick the lockedQC.node to be not fixed. Thus, they can pass the safety rule with any varied implementations they want. Thus, when seeing Byzantine proposals from malicious leaders in Attack 1, 2.1, and 2.2, all they need to achieve for Byzantine behaviors are to vote them with modified lockedQC.node. \\\\
Attacks 3, 4.1, and 4.2 are straightforward. However, detections of malicious voters are harder than detecting malicious leaders performing Attack 1, 2.1, and 2.2. One reason is the precision of detections is completely dependent on precision in Attacks 1, 2.1, and 2.2. Detections over Amnesia are independent, but detections on Attacks 3, 4.1, and 4.2 can be impacted if Attacks 1, 2.1, and 2.2 are not with a high precision rate. That is the price of the sudden death variant of Amnesia. Thus, detections over Attack 1, 2.1, and 2.2 must be made robust. \\\\The other reason that is when looking at Figure \ref{fig:hotstuff1}'s line 26 again, we can see an OR operator is checking the safety and liveness rule. Honest nodes will not agree with safety rules if malicious proposals come. However, they might pass the liveness rule that qc.viewNumber $>$ lockedQC.viewNumber. Normally, when there are no Accidental behaviors like message loss issues, honest nodes will return False because the safety rule and liveness rule are neither passed. The safety rule is not passed because the incoming proposal's QC's node is not extended from the lockedQC.node. After all, the malicious leader of that proposal intentionally put a QC with a previous node. And the liveness rule cannot be passed because since the leader proposed an even less round number as view number, it will not be bigger than the current round number as view number as section \ref{sec:4.1.2} argues. However, when there's Accidental message loss, the liveness check can be passed unexpectedly, causing the honest node wrongly return True to agree to vote for the incoming malicious proposals. That is if this honest node is dead for multiple rounds, its lockedQC.node is never updated during these rounds, still leaving to be a small round number. And any incoming proposals with a bigger node number can be triggered to pass the liveness rule. Here's an example: when the honest node is dead in round 9, its lockedQC.node is 9. Then in round 13, the malicious node proposes a proposal with node 10 with round number 10, and now the honest node revives, still with lockedQC.node of 9 without any update. Then 10 is bigger than 9, and regardless of whether the safety rule is passed, the liveness rule check is tricked to return True. \\\\
The above scenario causes trouble in detecting malicious voters' behaviors by lowering the false positive rate because some dead honest nodes which are not updated lockedQC.node will be wrongly caught as malicious nodes in my first trial of detectors. Improvement will be discussed in section \ref{sec:6.4}. The above statement is just aiming to show that malicious voter behaviors are simple but harder to be detected than malicious leaders.\\\\
To sum up section \ref{sec:4}, these safety attacks are Attack 1, 2.1, 2.2, 3, 4.1, and 4.2, with liveness attacks "Attack 1" and "Attack 2" which will be directly called in the sections below. Byzantine behaviors are defended by the current HotStuff protocol, and thus cannot be carried out successfully. The next section will introduce how these Byzantine behaviors are defended using Sonnino's HotStuff codebase as a case study, describing the importance of additional detections binded with defense, and how detections work in high-level.\\


\section{Detections of attempts of Safety attacks for HotStuff}\label{sec:5}
Now let's start our detections. There're many variants of HotStuff, and I choose Alberto Sonnino's codebase of a minimal implementation of a 2-chain variant of the HotStuff consensus protocol. [9]
\begin{figure}
\hspace*{-3cm}
  \includegraphics[scale=1.1]{f11.PNG}
  \caption{referenced HotStuff codebase[9] running output}
  \label{fig:hotstuff11}
\end{figure}
\subsection{Detection playground: Sonnino's codebase}\label{sec:5.1}
\subsubsection{Overview}\label{sec:5.1.1}
The referred codebase[9] is written in Python and Rust. By following the README.md and wiki in the codebase, users can configure and run code in both local and remote AWS environments. Users can manually set parameters like node numbers, threshold running time, fault node numbers, etc. When running the codebase's benchmark, the simulation of transactions between nodes proceeds. Figure \ref{fig:hotstuff11} shows the outputs after the code is done running: Left is the output of overview situations of benchmark, and the right is the generated log of individual node's logging output during every transaction, like what block it committed, created, verified, voted, etc.\\\\
After finishing the whole detection experiments, the reasons I choose this codebase is verified again as the description in the referred codebase[9] describes: "small, efficient, and easy to benchmark and modify".[9] These traits foster the detections a lot because:\\\\
\textbf{Structure of messages are simplified: }The referred codebase's implementation [9] simplifies the data structures of each message. To check whether messages are the same, just observing whether QC are the same can help identify, which is simple but precise.\\\\
\textbf{Efficient implementation: }The transactions are very efficient in the referred codebase's implementation[9]. Setting benchmark to be run within 20 seconds, there can be over 100 transactions conducted in the local environment.\\\\
\textbf{Easy to modify: }The benchmark is easy to be modified. That is users can modify the code with many types of additional logs and simulations of attacks. Additional logs will be discussed in the next section, and simulation of attacks are discussed in section \ref{sec:6.1}.\\
\subsubsection{Main helper for detections: Additional logs}\label{sec:5.1.2}
As the right part of Figure \ref{fig:hotstuff11} shows, logs are generated for users to observe situations that happen across the whole runtime of the benchmark. To observe more information, the users can add additional logs to the codebase. Those logs in Figure \ref{fig:hotstuff11} is generated by the Rust statement "info!(...)". So, users can add additional info!(...) statements inside the code itself to observe more information, or for detection purposes. The main files for logging are proposer.rs, which generally logs the leader's behaviors, and core.rs, which logs all nodes' behaviors in a general fashion.
\subsection{Detecting Malicious Leaders}\label{sec:5.2}
Now let's dive into the real detection process. First, the easier task is detecting malicious leaders, which are detecting Attack 1, 2.1, and 2.2 in section \ref{sec:4.1}.
\subsubsection{Current Defence}\label{sec:5.2.1}
By looking at code in core.rs, defenses against those attacks are shown clearly in the referred codebase's implementation [9]:\\\\
\begin{figure}[t]
  \includegraphics[width=\linewidth]{f12.PNG}
  \caption{Referred codebase's Defence against Attack 1 [9]}
  \label{fig:hotstuff12}
\end{figure}
\begin{figure}
  \includegraphics[width=\linewidth]{f13.PNG}
  \caption{Referred codebase's Defence against Attack 2.1 [9]}
  \label{fig:hotstuff13}
\end{figure}
\begin{figure}[t]
  \includegraphics[width=\linewidth]{f14.PNG}
  \caption{Referred codebase's Defence against Attack 2.2 [9]}
  \label{fig:hotstuff14}
\end{figure}
\textbf{Defence against Attack 1: } In figure \ref{fig:hotstuff12}, there's a $make\_vote$ function intending for all replicas to form a data structure of the voting message and send the vote to the leader.  On line 101 there's a safety rule 1 variable checking whether the incoming proposal is with an increasing round number. If not, that means this proposal is invalid that the proposal is with the duplicated round number with previous proposals. That is not acceptable because as Attack 2.1 and 2.2 do, malicious leaders can propose a proposal with the previous round number to be branched from previous nodes for double-spending. Thus, safety check 1 is here. However, attacks 2.1 and 2.2 can be blocked in previous functions, which will be discussed later. And for line 102's safety rule 2, that is what to defend against Attack 1, because attack 1 is proposing with normal block round number, but with a QC that is embedded with a round number less than the supposed QC's round number. This is a QC check intending to check whether the leader modifies QC to attempt branching from the previous node. Thus, on line 108, if either safety rule 1 or 2 is violated, then that violated safety rules, and will be defended by returning None.\\\\
\textbf{Defence against Attack 2.1: }As above said, attacks 2.1 and 2.2 can be defended in the $make\_vote$ function, but when I did the detection, I found these two attacks can be blocked in earlier stages. In figure \ref{fig:hotstuff13}'s line 341, there's a conditional statement in $process\_block$ function that is intending to process the block made. That statement checks whether the block made is with a round number bigger than the current round number. This was intended to avoid "Attack 2" in section \ref{sec:4.1.3} which is a liveness attack of sending a proposal with the round number even bigger than the current round number. But note that there's a not equal operand checking that, which means a round number smaller than the current round number will still fall into this if statement and be handled explicitly with forfeiting the block. Thus, attack 2.1 is defended since attack 2.1 is to make a block with a less round number than the current one.\\\\
\textbf{Defence against Attack 2.2: }Although attack 2.2 is still with less round number than the current round number, it is not defended by the conditional statement in defending against attack 2.1. Instead, attack 2,2 is defended in an even earlier stage. In figure \ref{fig:hotstuff14}, there's a function called $handle\_vote$. This is earlier than making a block for defending attack 2.1 because proposals must be handled before making a block, and readers can read the main function at the bottom of the referred codebase's code [9] to re-verify this. In figure \ref{fig:hotstuff14} line 220 there's a leader check that verifies whether the leaders are consistent with two proposals with the same round numbers. If leaders are different, then that is attack 2.2 of different leaders proposing proposals with the same round number while the later proposal will be from the malicious leader. Then, this piece of code will not generate the proposal, and will just skip ignoring all processes later.\\\\
\begin{figure}
  \includegraphics[width=\linewidth]{f15.PNG}
  \caption{When there are no additional logs, Attacks 1, 2.1, and 2.2 all show the same behaviors of failing to connect to information}
  \label{fig:hotstuff15}
\end{figure}
\subsubsection{Why additional detections are needed}\label{sec:5.2.2}
Still, since we need to blacklist the malicious leaders, thorough detections are needed. However, current implementations in referred codebase[9] and real HotStuff code do not detect those attacks. Because as figure \ref{fig:hotstuff15} shows when replicas are successfully defending all attacks 1, 2.1, and 2.2, those attacks' output logs only log the same messages of "Failed to connect to..." information. That's it, and we cannot infer any information from this. Like if there are attacks here or just Accidental behaviors of cannot send messages due to network? Even if that is an attack, is it a safety attack or a liveness attack? even if we know it is a safety attack, what Byzantine behaviors are here? And even if we know what Byzantine behaviors are, who conducts these attacks and who reports this? There're many reasons that additional logs are needed, and the next section will show how.\\
\subsubsection{Addtional logs for further detections}\label{sec:5.2.3}
Additional logs are required to help identify Byzantine leaders by making replicas log more information when seeing proposals from the leaders, and parse them for the detector. Then, under the most ideal condition when all nodes are honestly logging the correct information, the detector will mainly compare with formulas in section \ref{sec:4.1} to check whether there's an attempt of safety attacks and report the proposer if it is with helps from additional logs. For example, the formula in section \ref{sec:4.1.1} is "R1 equals R2; QC1 not equals QC2", and the detector will check whether the round numbers between the proposals are the same and whether the QCs are different. If that is the case, then report the leader proposing the proposals.\\\\ But that is the most ideal situation since malicious nodes are existing to report dishonest information. So, I create a threat model to categorize all possible situations regarding checking malicious leaders. The threat model is there're two types of replicas: honest and Byzantine. The following part in this section introduce generally on how honest and Byzantine replicas behave, with specific implementation in section \ref{sec:6.1.2}.\\\\
\textbf{Honest replicas: }Honest nodes will log additional information to help the detector identify safety attacks as instructed. That is honest nodes will automatically report Byzantine behaviors they observe from proposals sent by the leader. \\\\
\textbf{Adding another realistic situation as interference for the detector: Byzantine replicas and 3S mode threat model: }
There's still one curiosity about what the malicious nodes will do. That is if the malicious replica is the malicious leader's partner, what will it logs? I'm not assuming malicious nodes will be always simple enough to behave the same behaviors as honest nodes of reporting the bad leaders, which is selling out its malicious partner as the most ideal situation for the detector. It can do other unexpected behaviors to deceive the detectors. Also, does the content it logs affect the whole detection process? \\\\So, the following threat model called the "3S mode threat model" will set all possible behaviors malicious nodes will do, which is applied in all following sections.\\\\
\textbf{Simple mode: }Simple mode is malicious nodes will honestly log exactly what the honest node log when seeing possible malicious proposals. If it does that, it is selling out the malicious leaders, which is simple.\\\\
\textbf{Silent mode: }Silent mode is malicious nodes will log nothing when seeing malicious proposals. Like in the above code snippet the honest nodes will do many info! statements to report, but the malicious nodes will remain silent, and let the execution proceed.\\\\
\textbf{Storytelling mode: }Storytelling mode is malicious nodes will do storytelling behaviors by logging a statement reporting random nodes as leaders, which is not the malicious leader sending the incoming proposal. \\\\
Thus, the existence of the 3S mode threat model adds interference for the detector to find the leaders. In section \ref{sec:6.1.2}, specific implementations of simulations with the 3S threat model will be introduced.\\

\subsection{Detecting Malicious Voters}\label{sec:5.3}
In section \ref{sec:4.2}, people might underestimate the difficulty of detecting malicious voters due to their condition of attack and easy-to-understand Byzantine behaviors. However, detecting them is harder than detecting malicious leaders.
\subsubsection{Current Defence}\label{sec:5.3.1}
Since the condition of attacks for Attack 3, 4.1, and 4.2 are completely dependent on Attack 1, 2.1, and 2.2 respectively, that means if the leader's Byzantine behaviors are blocked, then Attack 3, 4.1, and 4.2 failed because the proposals they vote, handle, or process are forfeited before all replicas can see them. 
\subsubsection{Why additional detections are needed}\label{sec:5.3.2}
However, there's still no logging information indicating the malicious voters. Information shown in figure \ref{fig:hotstuff15} is still the output. When the police find the crime boss, they will start to find the boss' men under him. This still applies in HotStuff, since we want to blacklist all malicious nodes as early as possible. So, malicious replicas intending to support the malicious leaders are the targets of the blacklist. 
\subsubsection{Addtional logs for further detections}\label{sec:5.3.3}
This time the additional logs are added in both honest nodes and malicious nodes in three functions in Figure \ref{fig:hotstuff12},  \ref{fig:hotstuff13}, and  \ref{fig:hotstuff14} for Attack 1, 2.1, and 2.2 respectively, to show the summarizing message of what the nodes vote/process/handle. For the honest nodes, they will still report honest messages. For the malicious nodes, they will still follow the 3S mode threat model of behaving undefined behaviors. Here's a short introduction on additional logs to help detect Attacks 3, 4.1, and 4.2.\\\\
Honest replicas will always log the correct voting/processing/handling messages, like "I voted for leader X ...". For Byzantine replicas, all of these attacks are similar from the malicious replicas' perspectives. Malicious replicas will report honest messages in simple mode, report nothing in silent mode, and report wrong messages in storytelling mode. Then, the detector will use their behaviors to detect whether they are malicious with the basic check and advanced check. The basic check is for detecting malicious nodes in simple mode, while the advanced check is for detecting malicious nodes in the other two modes. The implementation details are in Section \ref{sec:6.1.3}.

\section{Implementation and Evaluation}\label{sec:6}
If section \ref{sec:5} introduces additional logs for detections in a high-level manner, then this section will touch low-level implementation of section \ref{sec:5}. Code can be accessed in either the Appendix or the git repository https://github.com/Exilehead/comp0064-dissertation. First, we will get into the low-level details of my \textbf{method} of experiments: simulation of attacks. Next, I will introduce my detector with specific implementation in the Appendix section. Then, we will have the first evaluation with a tester. Since the result is not reaching a close to perfect result, there's an improvement on the detector on eliminating more liveness attacks or Accidental scenarios. Then we will have the last evaluation with a close to perfect result, but still some limitations to be discussed in section \ref{sec:7}.
\subsection{Simulation of attacks and modifications on replicas' responses}\label{sec:6.1}
By simulation of attacks, all attacks mentioned in section \ref{sec:4} can be carried out. Also, with modifications over responses of replicas, detection difficulty is eased. The process flows like this: setting the occurrence of all attacks, adding additional logs for replicas for detecting malicious leaders, and modifying replicas' logs for detecting malicious voters themselves. Please refer to Appendix \ref{appendix:proposer} and \ref{appendix:core} for specific implementation code and comments. \\
\subsubsection{Setting occurrence of attacks}\label{sec:6.1.1}
There're two types of simulation: hard-coded method and random method. The hard-coded method manually assigns variables in Referred codebase[9] that in round X the attack will be triggered, while the random method is for each trial of attacks the round of occurrences is randomized. I've done both methods and the results are based on them too, but for the simplicity of comprehending the code and to verify whether my results are reliable with pulling my code in GitHub, I just put the hard-coded version in GitHub and will use the hard-coded version in this paper for discussion below.\\\\
Overall, all attacks from leaders are simulated in the $generate\_proposal$ function. the original function is for leaders to generate proposals and send them to other replicas. The original code of sending proposal functionality is this::\\
\begin{verbatim}
self.tx_proposer
    .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
    .await
    .expect("Failed to send message to proposer");
\end{verbatim}
Then, attacks are built based on appending code below the above piece of code or modifying this piece of code.\\\\
\textbf{Simulating Attack 1: }Simulation of attack 1 is sending multiple proposals with different QCs in Sonnino code. The implementation is as follows:\\
\begin{verbatim}
// When the current round is 50, the leader does the Attack 1
if self.round == 50 {
    self.tx_proposer
        .send(ProposerMessage::Make(self.round, QC::genesis(), tc.clone()))
        .await
        .expect("Failed to send message to proposer");
}
\end{verbatim}
This code is appended after sending the normal proposal. It makes with the same round number as the original proposal as self.round, which is 50. But with a different QC::genesis(), which is QC branched from the genesis block, which is block 0. And the original proposal's second argument in the Make function is $self.high\_qc.clone$ which is equal to or slightly lower than 49. Thus, QC is different while round numbers are the same. That is the simulation of attack 1.\\\\
\textbf{Simulating Attack 2.1 and 2.2: }Attack 2.1 and 2.2 are sharing the same piece of code for simulation, because their main difference is whether leaders for two proposals are the same, and that is based on the random assignment of leader in each round: If the new leader is the same with the round of specified attack, it is Attack 2.1; If the new leader is different, then it is attack 2.2:\\
\begin{verbatim}
// When the current round is 40, the leader does Attack 2.1 or 2.2
if self.round == 40 {
    self.tx_proposer
        .send(ProposerMessage::Make(20, QC::genesis(), tc.clone()))
        .await
        .expect("Failed to send message to proposer");
}
\end{verbatim}
This piece of code replaces the original making proposal code. Instead, at round 40, it proposes with a round number of 20, and with QC still branched from genesis block which is branched from node 0. Thus, it is with the same round number as the early honest proposal in round 20 with a different QC. As above said, the chances of triggering attack 2.1 or 2.2 completely depend on who is the leader randomly assigned for this round.\\\\
\textbf{Liveness attacks Interference: } This paper does not only consider the most ideal situation. Besides interference from the 3S model,  I've added some liveness attacks as interference to show more confidence in the detector's correctness rate. Thus, here's the simulation of "Attack 1" and "Attack 2":\\
\begin{verbatim}
// When the current round is 60, the leader does the liveness "Attack 1"
if self.round == 60 {
    self.tx_proposer
        .send(ProposerMessage::Make(1,  QC::genesis(), tc.clone()))
        .await
        .expect("Failed to send message to proposer");

// When the current round is 70, the leader does the liveness "Attack 2"        
if self.round == 70 {
    self.tx_proposer
        .send(ProposerMessage::Make(100, QC::genesis(), tc.clone()))
        .await
        .expect("Failed to send message to proposer");
}
\end{verbatim}
Those liveness attacks are appended below the original code. For liveness "Attack 1", at round 60, proposes with round number 1, with QC still of genesis block of round number 0. Setting round 1 because sometimes it is not guaranteed that QC's round number + 1 equals the block's round number, but at round 1, the start of the transaction, its QC must be 0. So, this simulates the situation of "Attack 1", but still depends on whether the leader in real round 1 and this malicious proposal are the same. If not the same, then that is still the safety Attack 2.1. And for liveness "Attack 2", that is proposing with round number 100 which is bigger than current round number 70 to attempt branched from an uncommitted block, causing liveness interference.\\\\
To make the detection facing more challenges, I also add a very common liveness attack scenario, that is sending multiple identical proposals repetitively:\\
\begin{verbatim}
// When the current round is 20, sending the identical proposals again and again
if self.round == 20 {
    self.tx_proposer
        .send(ProposerMessage::Make(self.round, self.high\_qc.clone(), tc.clone()))
        .await
        .expect("Failed to send message to proposer");
    self.tx_proposer
        .send(ProposerMessage::Make(self.round, self.high\_qc.clone(), tc.clone()))
        .await
        .expect("Failed to send message to proposer");
    ................
}
\end{verbatim}
Still, this is appended below the original code. In round 20, there will be multiple identical proposals sent to other replicas to add interference for detections.
\subsubsection{Adding additional logs for replicas for detecting malicious leaders}\label{sec:6.1.2}\\\\
Now, we need to modify replicas' behaviors by adding additional logs to help identify Attacks 1, 2.1, and 2.2, as a low-level implementation of section \ref{sec:5.2.3}. In my setting, I use a random generator to identify honest nodes or Byzantine nodes before running the benchmarks. There's a array of [0, 100, 200, 300, 400, 500, 600, 700, 800, 900], and nodes with randomly assigned number [500, 600, 700] are Byzantine while with other numbers are honest nodes:\\\\

\textbf{Adding logging information for detecting Attack 1:} in figure \ref{fig:hotstuff12}, Rust code as follows are added for honest nodes, and explanations of why lines are added are in comments below in code:\\
\begin{verbatim}
// Only honest nodes report bad leaders for attack 1
if (nanos != 500 && nanos != 600 && nanos != 700){
    // If either safety rule 1 or 2 is violated
    if !(safety_rule_1 && safety_rule_2) {
        // Honest node directly reports there might be an attack 1
        info!("Attack 1 potentially detected!");
        // But this can be not attack 1. Instead, it can be liveness attacks or Accidental
        // behaviors. More explanations are explained below in the text.
        info!("But needs detector to further check 
        is it Attack 1");
        // check is safety rule 1 or 2 is satisfied
        info!("Is Safety Rule 1 satisfied? {}", safety_rule_1);
        info!("Is Safety Rule 2 satisfied? {}", safety_rule_2);
        // report who is the leader for this malicious proposal and related info
        info!("Proposal's Leader {} and round {} and 
        curr round {} and QC round {}", block.author, 
        block.round, self.round, block.qc.round);
        // show who am i
        info!("I am voter {} with nanos {}", self.name, nanos % 1000);
        // forfeit the vote
        return None;
    }
}
\end{verbatim}\\
Above is what honest nodes will do. There's one explanation there that needs to show why it does not necessarily attack 1. Because there can be liveness attacks or Accidental behaviors there that lead to delays in proposals sent. Liveness attacks can be the leader conducting "Attack 1" intentionally by sending multiple exactly same proposals to delay transactions, causing the round number in the block in safety rule 1 less than the current round number and cannot to pass safety rule 1. There can also be Accidental behaviors that with concurrency issues, the block is sent late in the next round, and will not pass this safety check either. So, the detector will ignore the Safety rule 1 behaviors. It just focuses on safety rule 2's behaviors that if it logs False, then it is attempting Attack 1. Then, the formula in section \ref{sec:4.1.1} is satisfied, since multiple blocks are with same round numbers but since safety rule 2 is violated, QCs are different. So, the detector will further deal with it later by checking returned result of safety rule 2 check.  \\\\
\textbf{Adding logging information for detecting Attack 2.1:} The following code with comments is added into Figure \ref{fig:hotstuff13}'s code snippet in Referred codebase[9] and generates additional logs after execution:\\
\begin{verbatim}
// Only honest nodes report bad leaders for attack 2.1
if nanos != 500 && nanos != 600 && nanos != 700 {
    // Still mimic previous behaviors for checking round numbers
    if block.round != self.round {
        // This can be attack 2.1
        info!("Attack 2 potentially detected!");
        //However, there's a possibility that this might
        // not be Attack 2.1, which will be
        //explained in explanations below
        info!("But needs detector to further check is it really Attack 2");
        // report the leaders with related info, and say what is the node reporting it
        info!("Proposal's Leader {} and round {}
        and curr round {} and QC round {}",
        block.author, block.round, self.round, block.qc.round);
        info!("I am voter {} with nanos {}", self.name, nanos % 1000);
        return Ok(());
    }
}
\end{verbatim}\\
The above Rust code is used to detect attack 2.1 by reporting leaders doing Byzantine behaviors. However, the detector cannot just parse this statement and naively reports that the leader is doing attack 2.1. Instead, there's still a possibility that this can be a liveness attack or Accidental behavior. Like section \ref{sec:4.1.3} says, The liveness "Attack 2" which is a block with a bigger round number than the current round number can fall into this if statement too, and can be wrongly treated as the safety attack 2.1. Thus, the detector should further check whether block.round is bigger than self.round or not to further see if is it Attack 2.1 or "Attack 2", referring to formula in section \ref{sec:4.1.2} to ensure the condition $Rb < RC$ is satisfied to be Attack 2.1. Also, there can be Accidental behaviors that there was message loss in the previous round, and the proposal in the previous round is sent in the current round, causing the non-matching block.round and self.round and wrongly interpreted as Attack 2.1. Thus, the detector must further handle it by checking whether transactions fall into the condition of formula in section \ref{sec:4.1.2} to achieve attack 2.1.\\\\
\textbf{Adding logging information for detecting Attack 2.2:} The following codes are inserted into Figure 14:\\

\begin{verbatim}
// Only honest nodes report bad leaders for attack 2.2
if nanos != 500 && nanos != 600 && nanos != 700{
    // If for two proposals with the same round number, leaders are different
    if block.author != self.leader_elector.get_leader(block.round) {
        // report the later proposal;'s leader, but this time 
        // report definitely that there's attack 2.2
        info!("Attack 2 definitely detected!");
        // report the bad leader, tell who am I, and 
        // stop the processing
        info!("Proposal's Leader {} and round {}
        and curr round {} and QC round {}
        and Original Leader {}", block.author,
        block.round, self.round, block.qc.round, 
        
        self.leader_elector.get_leader(block.round));
        info!("I am {}", self.name);
        ensure!(
            block.author == self.leader_elector.get_leader(block.round),
            ConsensusError::WrongLeader {
                digest,
                leader: block.author,
                round: block.round
            }
        );
        return Ok(());
    }
}
\end{verbatim}
Note that this time this report is final that the leader reported is definitely doing Attack 2.2. There's no liveness attack and Accidental behaviors interference there, because if two proposals are from different leaders but with the same round number as the core idea of Attack 2.2, then that cannot be liveness attacks because that is always intending to cause double spending to be branched from previous nodes, not delay or cause message loss. Accidental behaviors will never alter the content inside one proposal too, thus cannot alter the leader's name in one proposal. Thus, all the detector does to detect attack 2.2 is just parse this report message and directly detect attack 2.2 with its leaders here by checking with formula for conditions of achieving attack 2.2 in section \ref{sec:4.1.2}.\\\\
Overall, all the above are how additional logs are added for honest nodes to help make malicious leaders detected by my detector in section \ref{sec:6.2}. What the malicious replicas' based on the 3S mode threat model do not affect detecting malicious leaders actually, and here's the argument:\\\\
\textbf{Countering 3S mode by aggregated reporting results in one round: }The detector will not directly start to do additional checks on the bad leaders when seeing just one report message in one round. Instead, it will wait to receive more messages in each round until seeing a proposal from the next round. Then, since there can be at most f malicious nodes but 2f+1 honest nodes at least, 2f+1 is more than f. Thus, the detector will look at the aggregated results by seeing which leader name is reported most of the time in each round. The leader with the most appearances is potentially malicious leaders and will fall into additional checks. The 3s interference does not work here because if the malicious leader is in silent mode, it just loses a chance to add a vote to frame an innocent node up. If it is in storytelling modes, even if f malicious nodes're framing exactly one innocent node up, the f votes are less than the 2f+1 votes from honest nodes reporting the true malicious node. Thus, the 3S mode interference is taken away.\\\\
For detecting Attacks 1, 2.1, and 2.2, malicious nodes 3S mode behaviors are not used to parse to find the malicious voters, which are those malicious nodes themselves. But in section \ref{sec:6.1.3}, parsing their 3S statements are very crucial to detect their appearances.\\
\subsubsection{Modifying responses from voters for detecting malicious voters}\label{sec:6.1.3}
Section \ref{sec:5.3.3} introduces detections over sections 3, 4.1, and 4.2, but here is to show the low-level implementation details.\\\\
\textbf{Modifying logging information for detecting Attack 3: } the following code snippet is added: \\
\begin{verbatim}
// Mode 1 means simple mode from the malicious node, showing who am I and 
// what did I vote
if mode == 1 && (nanos % 1000 == 500 || nanos % 1000 == 600
|| nanos % 1000 == 700) && !safety_rule_1 && !safety_rule_2 {
    info!("I'm voter {} voting for block {} 
    with round number {} with QC {} from leader {}"
    , self.name, block, block.round, block.qc.round, block.author);
// Mode 2 means silent mode from the malicious node, showing no log
} else if mode == 2 && (nanos % 1000 == 500 || nanos % 1000 == 600
|| nanos % 1000 == 700) && !safety_rule_1 && !safety_rule_2 {
    info!("?");
// Mode 3 means storytelling mode from the malicious node, showing
// I'm voting for that proposal but the QC it lies as true QC 
}else if mode == 3 && (nanos % 1000 == 500 || nanos % 1000 == 600
|| nanos % 1000 == 700) && !safety_rule_1 && !safety_rule_2 {
    info!("I'm voter {} voting for block 
    {} with round number {} with QC {} from leader {}"
    , self.name, block, block.round, block.round-1, block.author);
// Honest nodes just tell the honest message, but normally never reach this
// when there's malicious behaviors because the honest nodes have already
// blocked the proposal before
}else {
    info!("I'm voter {} voting for block {} 
    with round number {} with QC {} from leader {}",
    self.name, block, block.round, block.qc.round, block.author);
}
\end{verbatim}\\
The above shows 4 conditional statements, stated in the comments above. Additional logs are added too, and the high-level explanation of how these can be used to detect malicious voters here and avoid 3S mode interference is as follows: The detector has stored all related information of the malicious leader and its proposal into $proof\_of\_attempt\_of\_safety\_attack$ as a list of storing all malicious leaders for now. Then, there's a naive check and an advanced check.\\\\
The naive check is checking whether there are simple mode behaviors from malicious voters. That is for the generated logs, collecting all additional logs information above. Then, collect all "I'm voter X voting for block Y with round number Z with QC A from leader B" statements there and parse them into the data structure specified in the detector and generate all voters' voting messages, and put them into a list. Then, iterate the list and compare it with all elements(reported malicious leaders objects) in $proof\_of\_attempt\_of\_safety\_attack$. If there's a matching round number, QC's round number, and matching reporting leader, then this voter is doing Byzantine behavior attempting to attack 3, and storing it as malicious.\\\\
The advanced check is for silent mode and storytelling mode. The check first does a reversible check by elimination method for silent mode. That is for each proposal attempting Attack 3, check who didn't report his leaders. Because the honest nodes are forcibly set to report the leader, then the nodes that don't report the leader are very possible to be malicious nodes. So in my detector, I iterate the voter list again. The log parser has already recorded all nodes' public keys participating in the transaction. For one malicious proposal, it will check the voter list to see who votes for them and mark the voter's public key as innocent. Then, the public key which is not marked as innocent is reported as a malicious node, because it is not voting. And then the next check is for checking nodes doing storytelling mode. That is checking in the voter list if is there any voter voting with the same round number with the malicious proposal, but with a different QC's round number. This check failed to identify malicious nodes initially because remember Attack 3 is voters voting for multiple proposals with the first proposal honest, and innocent voters voting for the first proposal is wrongly captured as malicious because the honest proposal must have a matching round number with the malicious proposal's but with different QC's round number. So, what I fixed was doing a partial ascending sort by the proposal's initiated time. For example, if a malicious voter voting for two proposals with round number 15 while voting for the honest one with a QC of 14 and the bad one with qc of 12, then (15,14) pair is in front of (15,12), and the proposals behind like (15,12) are the malicious one. Honest nodes just vote for one proposal, and since malicious nodes who just voted for one malicious proposal in silent mode has been caught, so all nodes just vote for one proposals are ignored here. Thus, just check the votes voting for the later proposals but with non-matching QC numbers will have very high correctness of being reported, unless there's liveness attack situation or Accidental behaviors, which will be explicitly handled in section \ref{sec:6.4}. \\\\
For attack 4.1 and 4.2, the additional logs code, basic check and advanced check is very similar, except that they are stored as handler and processor lists.\\\\
\textbf{Modifying logging information for detecting Attack 4.1:} The code is as followed in $process\_block$ function:\\\\
\begin{verbatim}
// Mode 1 means simple mode from the malicious node, showing who am I and
// what did I process
if mode == 1 && (nanos % 1000 == 500 || nanos % 1000 == 600|
| nanos % 1000 == 700) && block.round != self.round {
    info!("I'm processor {} processing for block {} 
    with round number {} with QC {} from leader {}", 
    self.name, block, block.round, block.qc.round, block.author);
// Mode 2 means silent mode from malicious node, showing no log
} else if mode == 2 && (nanos % 1000 == 500 || nanos % 1000 == 600||
nanos % 1000 == 700)&& block.round != self.round {
    info!("?");
// Mode 3 means storytelling mode from malicious node, showing
// Im processing for that proposal but the QC it lies as true QC
}else if mode == 3 && (nanos % 1000 == 500 || nanos % 1000 == 600||
nanos % 1000 == 700)&& block.round != self.round {
    info!("I'm processor {} processing for block {} 
    with round number {} with QC {} from leader {}", 
    self.name, block, block.round, block.round-1, block.author);
// Honest nodes just tell honest message, but normally never reach this
// when there's malicious behaviors because the honest nodes have already
// blocked the proposal before
}else {
    info!("I'm processor {} processing for block {} 
    with round number {} with QC {} from leader {}",
    self.name, block, block.round, block.qc.round, block.author);
}
\end{verbatim}\\\\
\textbf{Modifying logging information for detecting Attack 4.2:} the code is as followed in $handle\_vote$ function:\\\\
\begin{verbatim}
// Mode 1 means simple mode from malicious node, showing who am i and
// what did I handle
if mode == 1 && (nanos % 1000 == 500 || nanos % 1000 == 600|| 
nanos % 1000 == 700) && 
block.author != self.leader_elector.get_leader(block.round) {
    info!("I'm handler {} handling for block {} 
    with round number {} with QC {} from leader {}", 
    self.name, block, block.round, block.qc.round, block.author);
// Mode 2 means silent mode from malicious node, showing no log
} else if mode == 2 && (nanos % 1000 == 500 || nanos % 1000 == 600|
| nanos % 1000 == 700) && block.author != self.leader_elector.get_leader(block.round) {
    info!("?");
// Mode 3 means storytelling mode from malicious node, showing
// Im handling for that proposal but the QC it lies as true QC
}else if mode == 3 && (nanos % 1000 == 500 || nanos % 1000 == 600||
nanos % 1000 == 700) && block.author != 
self.leader_elector.get_leader(block.round) {
    info!("I'm handler {} handling for block {} 
    with round number {} with QC {} from leader {}",
    self.name, block, block.round, block.round-1, block.author);
// Honest nodes just tell honest message, but normally never reach this
// when theres malicious behaviors because the honest nodes have already
// blocked the proposal before
}else {
    info!("I'm handler {} handling for block {} 
    with round number {} with QC {} from leader {}", 
    self.name, block, block.round, block.qc.round, block.author);
}
\end{verbatim}\\
These are like attack 3 with a similar basic check and advanced check method, and all detection, for now, have not considered eliminating liveness attacks or Accidental behaviors, and some bugs there. These will be discussed in section \ref{sec:6.4}.\\\\

\subsection{Building the Detector script}\label{sec:6.2}
Finally, we come to the detector itself. In this subsection, major functions in the detector file $bft\_detecter.py$ is introduced. So, the whole code is still accessible in the Appendix or my git repo, and please refer to the code for understanding the following explanations.\\
\subsubsection{Log Parser}\label{sec:6.2.1}
The log parser is parsing those "info!" function statements into useful information. Here're specific functions:\\\\
The parseLog function will first extract all nodeX.log files which are generated by each node. Then, it will from each line get information including:\\
1. Node name for the node that is generating a log for each file.\\
2. Check which block is created by who and related information.\\
3. Detect Attack 1 by checking whether safety rule 2 is violated.\\
4. Detect Attack 2 by checking related information.\\
5. After they are parsed, information is stored in some data structures in the code. Leader's attacks are mostly detected in this phase, and the following detection functions are used to infer voters' attacks.\\\\
Please refer to Appendix \ref{appendix:logParser} for specific implementation code and comments.
\subsubsection{Detection functions}\label{sec:6.2.2}
Now, let's see how detection functions go.\\\\
The attackReporter function will record reporters for attackers, that are honest nodes indeed reporting the malicious behaviors. They are eliminated from further check because they are reporting correct messages and are confirmed to be innocent, as section \ref{sec:6.1.3} mentions for the advanced check. \\\\
The detectAttackThree and detectAttackFour are used to detect voters' attacks. The additional logs help for detection and the detection algorithms are introduced in section \ref{sec:6.1.3} too. The general function flows go like this for each of them:\\\\
1. Gather all malicious leaders\\
2. Basic check: Find voters doing Attack in simple mode and see are formulas in section \ref{sec:4.1.1} and \ref{sec:4.1.2} are satisfied with the returned results from the log parser. If they are satisfied, then there are attacks there. Getting the malicious leaders and marking all voters voting for those leaders to be malicious, and generate proofs.\\
3. Advanced check: Find voters doing Attack in silent or storytelling mode. \\
4. Innocent elimination: Eliminate innocent nodes wrongly caught as doing safety attacks, which will be further introduced in section \ref{sec:6.4}.\\\\
Please refer to Appendix \ref{appendix:detectionFunc} for specific implementation code and comments.
\subsubsection{Proof of Attempts of Safety Attacks}\label{sec:6.2.3}
Finally, we are generating proof of attempts of safety attacks.\\\
The $remove\_duplicate\_safety\_attack$ function removes duplicate safety checks in the final list of storing safety check proof, or the proof will contain too many duplicated proofs.\\\\
The main function controls all the above, and will finally print the proof of attempts of safety attacks. The proof is fixed as constants as figure \ref{fig:hotstuff22} shows.\\\\
\begin{figure}
    \hspace*{-3cm}
  \includegraphics[scale=0.7]{f22.PNG}
  \caption{Proof of attacks as constants}
  \label{fig:hotstuff22}
\end{figure}
There's still one brief adding on that I've subdivided attacks from voters of 3, 4.1, and 4.2 into two for each attack. That is one if for detecting simple mode, which is a basic check, and mode 1 is representing it in my code. The other is for detecting silent or storytelling mode, which is an advanced check, and modes 2 and 3 are representing it in my code. For instance, attack 3.1 in the proof is showing that attack 3 in simple mode is detected, while 3.2 represents attack 3.2 in either storytelling or silent mode is detected. The sample output is like in figure \ref{fig:hotstuff16}. This sample output indicates that the node with the public key, which is the name for simplicity, JjYwSbJUt4Tyskee is performing attacks 1, 2.2, 4.1, 4.2, while tcIawzh+XwWf9tjQ is performing attack 3.2, 4.1, and 4.2. So, there're two malicious nodes in the whole transactions process in this run of the simulation, with proof specifying what malicious behaviors they have done as shown in figure \ref{fig:hotstuff16}. Thus, the consensus protocol must report nodes with public keys of JjYwSbJUt4Tyskee and tcIawzh+XwWf9tjQ to all nodes with what misbehaviors they've conducted, \textbf{so honest nodes can blacklist these two nodes and never conduct any transactions with them.} \\\\
That's it for the detector from log parsing to blacklisting of malicious nodes. More details of implementations are shown in the code in $bft\_detector.py$. If readers are interested, please take a look at my git repo.
\begin{figure}
  \includegraphics[width=\linewidth]{f16.PNG}
  \caption{Sample output of proof of malicious behaviors}
  \label{fig:hotstuff16}
\end{figure}
\subsection{Tester}\label{sec:6.3}
To evaluate how precise the detector works, there must be an automated tester to test it. The tester suite consists of $bft\_script.py$, which is for automatically generating logs with multiple runs, $bft\_detector.py$, which is the tester itself generating the results, and the logs folder containing those logs for testing.
\subsubsection{Measurements}\label{sec:6.3.1}
The measurement scale I choose to test the accuracy of detection is to test the false positive rate and false negative rate for the basic check, and an advanced check for checking whether the reported malicious voters are indeed doing the reported attacks. \\\\
For the basic test, I abbreviate \textbf{false positive rate into Precision and false negative rate into Recall} by borrowing ideas in Professor Murdoch's COMP0055's ppt. [10] Precision is calculated as follows:\\
\[Precision = SupposesMaliciousNodes / (WronglyCaughtHonestNodes+SupposesMaliciousNodes)\] \\
That is if there are 10 malicious nodes, and if there's one honest node wrongly caught as malicious, then Precision = 10/(1+10).\\\\
And the Recall is calculated as follows:\\
\[Recall = SupposesMaliciousNodes / (IgnoredMaliciousNodes+SupposesMaliciousNodes)\]\\
That is if there are 10 malicious nodes, and the detector fails to identify one of them as malicious, then Recall = 10 / (1+10).\\\\
Above is the basic check. For the advanced check, it is checking whether malicious voters captured are really doing the attacks. For example, if the malicious voters are only doing Attack 3, and were caught as doing both Attack 3 and Attack 4.1, then that is not correct. The correctness is calculated as follows:\\
\[Correctness = [SupposedAttackIndex] == [ActualAttackIndex] ? 1:0\]\\
That is if the malicious node doing both Attack 3 and 4.1 are detected as indeed doing them exactly, then it returns 1. Else, return 0.\\\\
Above are the measurements for testing whether my detector works well. And there's another type of measurement which are attacks in sample categories. In the "logs" folder of my git repository, there are 23 sets of logs for the whole experiment, with 20 folders of logs for each set, with 9 nodes' logging information in each folder. There are about 4500 lines of logging information for each node, so the whole experiments parse about $4500*9*20*23=$\textbf{18630000} lines of logs, which is a huge number of lines, aiming to provide the most accurate and reliable results. The performance is not redundant under the local benchmark environment, since the referred codebase does an excellent job on saving performance cost.[9] The partial information of individual node's logging information with my additional logs looks like what is in the Appendix \ref{appendix:partialLoggingInfo} for reference. The 23 sets of logs are divided into the following categories:\\\\
\textbf{Individual Attack 1 and 3}: That is the simulation of attacks that only have Attack 1 and 3 there. Hard-coded version is used here.\\
\textbf{Individual Attack 2.1 and 4.1}: That is the simulation of attacks only has Attack 2.1 and 4.1 there. Hard-coded version is used here.\\
\textbf{Individual Attack 2.2 and 4.2}: That is the simulation of attacks only has Attack 2.2 and 4.2 there. Hard-coded version is used here.\\
\textbf{Individual Attacks}: That is the simulation of attacks can have random individual attacks here. The random version is used here. \\
\textbf{All attacks, one leader for attack 1, 2 for each}: That is all safety attacks 1, 2, 3, 4 in this paper are included in this scenario. Hard-coded version is used here.\\
\textbf{All attacks, one leader for attack 1, 2 for each, with liveness interference}: That is all safety attacks 1, 2, 3, 4 in this paper are included in this scenario, with all liveness attacks "Attack 1", "Attack 2" and multiple same proposals
 scenarios in this paper are included for interference. Hard-coded version is used here.\\
\textbf{All attacks, multiple leaders for attack 1, 2 for each}: That is there're all attacks 1, 2, 3, 4, but Attacks 1 and 2 are conducted multiple times with the same or different leaders. Hard-coded version is used here.\\
\textbf{All attacks, one leader doing both attack 1, 2 at the same round}: That is an edged case that one leader doing all attacks 1, 2, 3, 4 at the same round.\\\\
Finally, how the tester knows who is malicious and their attacks are by parsing the logs too, but with some additional logs that cannot be used by the detector. That is the malicious nodes will manually report that it is doing attacks, and the tester just parses this information. In Figure \ref{fig:hotstuff20}, if there's an indication of "PYTHON DETECTOR CANNOT DETECT FROM HERE" and "PYTHON DETECTOR CAN DETECT FROM HERE", then logs between these two statements can only be parsed by the tester, not the detector because the logs between two statements are due to cheating of revealing who is doing what. The detector can only parse logs outside those two statements like codes start from line 3402 in Figure \ref{fig:hotstuff20}.\\\\
Now, after defining those measurements, let's see how the whole results generation works.
Meanwhile, please refer to Appendix \ref{appendix:tester} for specific implementation code and comments for the tester and \ref{appendix:scripts} for generation of logs.
\subsubsection{Generating and Evaluating results}\label{sec:6.3.2}
First, we need to generate logs. $bft\_script.py$ is responsible for generating 20 sets of logs for each subcategory of samples in my logs folder. For instance, the $1\_10\_1ML\_10\_30$ folder is a subcategory of "All attacks, one leader for attack 1, 2 for each". The folder name is interpreted as there's 1 fault node, 10 nodes in total. There's one malicious leader, and at round 10 there's attack 1, and at round 30 there's attack 2.\\\\
After the log is generated, then the $bft\_tester$ starts testing by scanning all sets of logs inside folders like $1\_10\_1ML\_10\_30$. The tester will do the basic check and advanced check simultaneously. The output looks like in figure \ref{fig:hotstuff17}. 
Then, collecting the precision, recall, and correctness at the bottom of figure \ref{fig:hotstuff17}. Since there're multiple subsets under one sample category, then the aggregated precision/recall/correctness is calculated with their average and standard deviation. For example, "All attacks, one leader for attack 1, 2 for each" has the subcategory of $"1\_10\_1ML\_10\_30"$, $"1\_10\_1ML\_10\_50"$, $"1\_10\_1ML\_20\_60"$, $"1\_10\_1ML\_30\_70"$, $"1\_10\_1ML\_25\_90"$ in my git repo, and the their precision/recall/correctness for the supergroup "All attacks, one leader for attack 1, 2 for each" is calculated by total divided with 5 for average and standard deviation. Names with $liveness\_interference$ belong to the supergroup "All attacks, one leader for attack 1, 2 for each, with liveness interference". Names with $null$ are individual attacks for Attack 1 and 3 or Attack 2 and 4 based on their specific names, for instance, "$1\_10\_1ML\_null\_60.2\_m1$" means there's no attack 1 but there's attack 2.2 in round 60, which means there's only attack 2 and 4 in this trial under m1. If there's "m1"/"m2"/"m3" in the name, that means it is under the 3S model of simple/silent/storytelling modes. If there's a "hybrid" in the name, that means it is under the 3S model with 3 modes coexisting within this trial in a hybrid manner.
\begin{figure}
  \includegraphics[width=\linewidth]{f17.PNG}
  \caption{Sample output of the tester}
  \label{fig:hotstuff17}
\end{figure}
\begin{figure}
\hspace*{-3cm}
  \includegraphics[scale=0.7]{f18.PNG}
  \caption{Precision for both normal and improved detector}
  \label{fig:hotstuff18}
\end{figure}
\begin{figure}
  \hspace*{-3cm}
  \includegraphics[scale=0.7]{f19.PNG}
  \caption{Recall for both normal and improved detector}
  \label{fig:hotstuff19}
\end{figure}
\begin{figure}
  \includegraphics[width=\linewidth]{f20.PNG}
  \caption{Additional logs as cheating for tester, not detector}
  \label{fig:hotstuff20}
\end{figure}
\\\\After the tester is done, the final results come out. The results of each set of logs are in Appendix \ref{appendix:results}. Then, compute the aggregated average and standard deviation for logs within each supergroup, and generate the graphs. The generated graph is shown in \ref{fig:hotstuff18} for precision and figure \ref{fig:hotstuff19} for recall. The x-axis represents the sample categories, and the y-axis represents the percentage. There're two bars for each sample category, and the \textbf{orange bars} on the left for each category are the generated results of my first drafted detector. Before discussing any problem, let's see the \textbf{strength} of this detector by mentioning the high precision and recall it produces:\\\\
\textbf{1. The Precision and Recall are all over 80 percent, which means this detector works in a satisfactory manner by reporting most attacks correctly.}\\
\textbf{2. Attacks subcategories of "All attacks, one leader for attack 1, 2 for each" are showing 99.22 percent of precision and 98.82 percent of recall, which are both close to perfect. That means when there are multiple safety attacks presented in all transactions, the detector works well.} \\
\textbf{3. Attacks subcategories of "All attacks, multiple leaders for attack 1, 2 for each" are showing 97.44 percent of precision and 98.28 percent of recall, which are still both to perfect. That means when there are multiple safety attacks even conducted by multiple leaders, then the detector can find all of them with their malicious voters correctly.}\\\\
From above, we can see when there're multiple attack presented in all transactions, the detector works well with high precision and recall. That strength reveals that when there are more attacks, then it is easier to detect them correctly. However, other subcategories are not showing close to perfect precision and recall, and from the charts, there're two main \textbf{weaknesses} there causing unsatisfactory results: \\\\\\
\textbf{Problem 1. Individual attacks are even having worse precision and recall than multiple attacks existing simultaneously. Like "Individual attack 2.1 and 4.1" just has 87.37 percent of precision while "All attacks, one leader for attack 1, 2 for each" has 99.22 percent of precision.\\\\
Problem 2. Attacks with liveness interference are having just about 84 percent of the precision rate.\\\\}
Thus, there's room for improvement to make the precision and recall close to perfect. Then, only that is achieved, the advanced check can be preceded.
\subsection{Improving the Detector script for better accuracy}\label{sec:6.4}
So, I need to mitigate the above two deficiencies in the previous subsection. After observing the logs stdout, I found both are caused by problems related to liveness attacks and Accidental behaviors. \\\\Problem 1 is caused by Accidental behaviors that sometimes the attack is not conducted due to Accidental behaviors of cannot sending the proposals. That is more of the tester's fault, because if the attack is not carried out successfully, then there are actually no attacks there. That is a single point of failure issues because in other sample categories there're many attacks that even if one of them suffers from Accidental stuff, other attacks are still carried out normally. But individual attacks just have one attack, and the tester will wrongly output a lower recall since it thinks the detector does not capture that attack, while that attack is not carried out successfully. \\\\
Problem 2 is caused by ignorance on handling those liveness attacks. Those liveness attacks are hard to be differentiated from Accidental behaviors, but handling them will bring out a very good advantage which is identifying those behaviors as liveness will also take away Accidental behaviors showing the same outputs. Thus, the next section will explicitly handle liveness attacks in the detector and tester.
\subsubsection{Improving Precision and Recall by identifying liveness attacks}\label{sec:6.4.1}
For the detector, more functions are added to further check whether some nodes doing liveness attacks or Accidental stuff or misinterpreted as doing safety attacks. If they are doing liveness attacks, they are still honest nodes under the settings of this paper. \\\\
The detectLivenessOrAccident and detectLivenessWhichIsActuallySafetyAttack function will handle liveness situation. The detectLivenessOrAccident will check if there are "Attack 1" and "Attack 2" when doing the safety attack checks. If they are doing "Attack 1" and "Attack 2" truly, they are interpreted as doing liveness attacks and are innocent. (Though in the real world they are still malicious) And the detectLivenessWhichIsActuallySafetyAttack will do additional checks on eliminating liveness attacks of sending the same proposals again and again, or some typical Accidental behaviors like the honest nodes fail to report the malicious due to message loss will be considered as honest again. After calling the detector again, the precision is improved with a huge jump.\\\\
The tester is that it will stop considering malicious nodes failing to do the attacks to be malicious. They are doing nothing, even no Byzantine behaviors, how can we ensure that they are malicious? This is a scientific project, not a psychological project. Thus, the recall rate is improved greatly too.\\\\
Please refer to Appendix \ref{appendix:eliminateLiveness} for specific implementation code and comments.
\subsubsection{Bug fixes on both detector and tester}\label{sec:6.4.2}
There are also some bug fixes commented in the code in Appendix \ref{appendix:detectionFunc}. They are not limited to wrong sorting keys, ignored conditions, Accidental behaviors' ignorance, etc.
\subsubsection{Evaluating results}\label{sec:6.4.3}
Then, after running the tester again, I get the updated precision and recall again. These can be still seen in figure \ref{fig:hotstuff18} and \ref{fig:hotstuff19}, with the right bars for each sample group as the improved version. We now can see the precision and recall are both close to 100 percent. Two problems stated before are mitigated. Problem 1 is mitigated since "All attacks, one leader for attack 1, 2 for each, with liveness attacks interference" is improved to be 100 percent over the original 83.96 percent for the precision. The problem 2 is mitigated since individual attacks are all improved quatatively based on precision and recall, like "Individual attack 2.1 and 4.1" is improved to be 100 percent over the original 87.37 percent for the precision and 99.63 percent over the original 88.86 percent for the recall. So, the improved detector works quantitatively fine for attacks proposed in this paper. This also shows that the main reason the first drafted detector does not work perfectly fine is due to ignorance on liveness attacks/accidental behaviors' eliminations. However, the reason they are still not 100 percent for all is still due to accidental behaviors, which is introduced as a minor limitation in section \ref{sec:7.1}.\\\\
To verify the existence of accidental behaviors, the advanced check proceeds as figure \ref{fig:hotstuff21} shows. That further shows that the reason it is not close to 100 percent is still due to Accidental behaviors, causing unexpected behaviors like voters sometimes wrongly interpreted it as doing less attacks than its actual Byzantine behaviors, which will be explained below.\\\\
So, the detector works with close to perfect precision and recall, leading to a successful production of this project, but there are still limitations there. One minor one from the results, and one major one from the whole set. The next section discusses this.
\begin{figure}
\hspace*{-3cm}
  \includegraphics[scale=0.7]{f21.PNG}
  \caption{Advanced check on the correctness of seeing is the voter doing exact attacks, by comparing detector's results and actual results}
  \label{fig:hotstuff21}
\end{figure}
\section{Limitation}\label{sec:7}
Now, it's time to discuss the limitations seen in this paper.
\subsection{Minor issue: Accidental behaviors' interference}\label{sec:7.1}
Overall, figure \ref{fig:hotstuff21} shows that accidental behaviors can cause the detector fails to identify that one node is exactly doing what attacks. Even if I explicitly handled some liveness attacks and Accidental behaviors with the same behaviors with those liveness attacks, there're still some edge-cased Accidental behaviors that are very hard to be handled since they are causing Byzantine behaviors abnormal shown in additional logs. From figure \ref{fig:hotstuff19} we can see the recall of "All attacks, one leader doing both attack 1, 2 at the same round" is still about 97 percent. By manually checking I found there are Accidental behaviors that can sometimes make malicious nodes report the wrong voting messages as doing Storytelling mode under Attacks 4.2, but the honest nodes will not report there's Attack 2. The detector and tester did handle the situation of non-reports from honest nodes as no attacks there, but that is all-or-nothing. The detector and tester only handle when both honest and malicious nodes do/don't react, but not if honest nodes don't react but malicious nodes react with mode 3. Attack 2 takes place indeed, but malicious nodes cannot be caught as doing attacks, causing worse recall. That is an edge-case situation. I've checked with additional logs, simulations of attacks, detectors, and tester but found no issues. That might be caused by concurrency issues on log output when two different attacks take place at the same round. That is an Accidental behavior, but very hard to handle.

\subsection{Major issue: Cannot detect Liveness attacks}\label{sec:7.2}
The above minor situation does not affect the detector a lot, since if the leader starts another Byzantine behavior, I can still detect malicious voters later. But the major issue of this paper, as mentioned multiple times, is this is a safety attack detector, not a liveness attack detector. Detecting liveness attacks is extremely hard, and there's no current work successfully identifying liveness attacks with confidence. The main reason is liveness attacks sometimes show the same behaviors as Accidental behaviors to honest nodes, and differentiating them is very hard for those honest nodes. That can lead to a low false positive rate that many nodes just doing Accidental behaviors are wrongly caught as liveness attackers, like if message loss and resend the same proposals again, then that is same behaviors with light DDoS of sending same proposals again and again [19]. Thus, this is very hard to differentiate the problem.
\section{Conclusion and Future Work}\label{sec:8}
So, this paper introduces some new variants of Byzantine behaviors attempting safety attacks in HotStuff, and how the detections work to detect them. Defense is already in place, and with additional detection mechanisms by my detector returning a close to perfect result, the attackers can be indicated and blacklisted for further punishment. But this detector can only detect safety attacks successfully. \\\\
Future work, as section \ref{sec:7} states, must be focusing on liveness attacks detector, especially focusing on how to differentiate between liveness attacks and Accidental behaviors. Since liveness attacks are showing the same behaviors as Accidental behaviors to honest nodes, detecting liveness attacks is still a long way to go. One potential breakthrough can be adding support for network monitoring tools like Wireshark[26] to be able to detect distributed setups like HotStuff to test network speed supporting transaction flows. If the network is normal, then that must be liveness attacks existing. In addition, let's return to the theme. The existing HotStuff does not support detections over attempts of safety attacks. And the handling of detection of safety attacks should be built into a module in the consensus protocol that does not affect the normal operation of BFT-based blockchains. Future work must also focus on detection and blacklisting over safety attacks as my detector do, which helps the current defense a lot to build an environment putting information security as the supreme goal.

\begin{thebibliography}{9}
\bibitem{}
Lamport, L., Shostak, R., & Pease, M. (2019). The Byzantine generals problem. In Concurrency: the works of leslie lamport (pp. 203-226).
\bibitem{}
Vukoli, M. (2015, October). The quest for scalable blockchain fabric: Proof-of-work vs. BFT replication. In International workshop on open problems in network security (pp. 112-125). Springer, Cham.
\bibitem{}
Douceur, J. R. (2002, March). The sybil attack. In International workshop on peer-to-peer systems (pp. 251-260). Springer, Berlin, Heidelberg.
\bibitem{}
Yin, M., Malkhi, D., Reiter, M. K., Gueta, G. G., & Abraham, I. (2018). HotStuff: BFT consensus in the lens of blockchain. arXiv preprint arXiv:1803.05069.
\bibitem{}
Dederichs, F., & Weber, R. (1990). Safety and liveness from a methodological point of view. Information Processing Letters, 36(1), 25-30.
\bibitem{}
Bano, S., Sonnino, A., Chursin, A., Perelman, D., Li, Z., Ching, A., & Malkhi, D. (2022). Twins: Bft systems made robust. In 25th International Conference on Principles of Distributed Systems (OPODIS 2021). Schloss Dagstuhl-Leibniz-Zentrum fr Informatik.
\bibitem{}
Jovanovic, P., Vasek, M. (2021). COMP0143 Cryptocurrencies Consensus Layer [PowerPoint slides]. Department of Computer Science, University College London.
\bibitem{}
Bano, S., Sonnino, A., Al-Bassam, M., Azouvi, S., McCorry, P., Meiklejohn, S., & Danezis, G. (2019, October). SoK: Consensus in the age of blockchains. In Proceedings of the 1st ACM Conference on Advances in Financial Technologies (pp. 183-198).
\bibitem{}
Sonnino, A.(2022) HotStuff [Source Code]. https://github.com/asonnino/hotstuff
\bibitem{}
Murdoch, S. (2021) Legality and ethics [PowerPoint slides]. Department of Computer Science, University College London. 
\bibitem{}
Blockchain Threat Report. (n.d.). N.p.: McAfee. Retrieved from https://www.mcafee.com/enterprise/en-us/assets/reports/rp-blockchain-security-risks.pdf
\bibitem{}
Raebra, S. A., & Vijayalakshmi, S. (2010). BYZANTINE BEHAVIOUR (B2)MITIGATING MIDWAY MULTICAST MISBEHAVIOUR (M4) IN ADHOC NETWORK. International Journal of Network Security & Its Applications (IJNSA), 2(3).
\bibitem{}
Niu, J., & Feng, C. (2020). Leaderless Byzantine fault tolerant consensus. arXiv preprint arXiv:2012.01636.
\bibitem{}
Diem (n.d.). Diem. Retrieved from
https://www.diem.com/en-us/
\bibitem{}
Celo (n.d.). Celo. Retrieved from
https://celo.org/
\bibitem{}
Cachin, C., Guerraoui, R., & Rodrigues, L. (2011). Introduction to reliable and secure distributed programming. Springer Science & Business Media.
\bibitem{}
Python. https://www.python.org/ 
\bibitem{}
Rust. https://www.rust-lang.org/
\bibitem{}
Javaid, U., Siang, A. K., Aman, M. N., & Sikdar, B. (2018, June). Mitigating loT device based DDoS attacks using blockchain. In Proceedings of the 1st Workshop on Cryptocurrencies and Blockchains for Distributed Systems (pp. 71-76).
\bibitem{}
Zhang, R., Xue, R., & Liu, L. (2019). Security and privacy on blockchain. ACM Computing Surveys (CSUR), 52(3), 1-34.
\bibitem{}
Karame, G. O., Androulaki, E., & Capkun, S. (2012, October). Double-spending fast payments in bitcoin. In Proceedings of the 2012 ACM conference on Computer and communications security (pp. 906-917).
\bibitem{}
Gai, F., Farahbakhsh, A., Niu, J., Feng, C., Beschastnikh, I., & Duan, H. (2021, July). Dissecting the performance of chained-bft. In 2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS) (pp. 595-606). IEEE.
\bibitem{}
Altarawneh, A. (2021). Liveness analysis, modeling, and simulation of blockchain consensus algorithms' ability to tolerate malicious miners.
\bibitem{}
Lamport, L. (2019). Time, clocks, and the ordering of events in a distributed system. In Concurrency: the Works of Leslie Lamport (pp. 179-196).
\bibitem{}
Dwork, C., Lynch, N., & Stockmeyer, L. (1988). Consensus in the presence of partial synchrony. Journal of the ACM (JACM), 35(2), 288-323.
\bibitem{}
Wireshark. https://www.wireshark.org/
\bibitem{}
Scicchitano, F., Liguori, A., Guarascio, M., Ritacco, E., & Manco, G. (2020, May). A Deep Learning Approach for Detecting Security Attacks on Blockchain. In ITASEC (pp. 212-222).
\bibitem{}
Ramanan, P., Li, D., & Gebraeel, N. (2021). Blockchain-based decentralized replay attack detection for large-scale power systems. IEEE Transactions on Systems, Man, and Cybernetics: Systems.
\bibitem{}
Pries, R., Yu, W., Fu, X., & Zhao, W. (2008, May). A new replay attack against anonymous communication networks. In 2008 IEEE International Conference on Communications (pp. 1578-1582). IEEE.
\bibitem{}
Ye, C., Li, G., Cai, H., Gu, Y., & Fukuda, A. (2018, September). Analysis of security in blockchain: Case study in 51-attack detecting. In 2018 5th International conference on dependable systems and their applications (DSA) (pp. 15-24). IEEE.
\bibitem{}
Ethereum. https://ethereum.org/en/
\bibitem{}
Zhao, X., Chen, Z., Chen, X., Wang, Y., & Tang, C. (2017, November). The DAO attack paradoxes in propositional logic. In 2017 4th International Conference on Systems and Informatics (ICSAI) (pp. 1743-1746). IEEE.
\end{thebibliography}
\appendix{}

\section{Source code for Simulation of attacks}
Code are written in Python[17] and Rust[18]. Here're source codes:
\subsection{Modified proposer.rs [9]}
\label{appendix:proposer}
\begin{lstlisting}[language=Rust]
    async fn make_block(&mut self, mut round: Round, qc: QC, tc: Option<TC>) {
        let qc_2 = qc.clone();
        // Generate a new block.
        let mut block = Block::new(
            qc,
            tc,
            self.name,
            round,
            /* payload */ self.buffer.drain().collect(),
            self.signature_service.clone(),
        )
        .await;
        //if !block.payload.is_empty() {
            info!("Created {}", block);
            info!("Created with Round number {} with QC {} ", round, qc_2.round);
            #[cfg(feature = "benchmark")]
            for x in &block.payload {
                // NOTE: This log entry is used to compute performance.
                info!("Created {} -> {:?}", block, x);
            }
        //}
        debug!("Created {:?}", block);
        // Broadcast our new block.
        let (names, addresses): (Vec<_>, _) = self
            .committee
            .broadcast_addresses(&self.name)
            .iter()
            .cloned()
            .unzip();
        let message = bincode::serialize(&ConsensusMessage::Propose(block.clone()))
            .expect("Failed to serialize block");
        let handles = self
            .network
            .broadcast(addresses, Bytes::from(message))
            .await;
        // Send our block to the core for processing.
        self.tx_loopback
            .send(block)
            .await
            .expect("Failed to send block");
        // Control system: Wait for 2f+1 nodes to acknowledge our block before continuing.
        let mut wait_for_quorum: FuturesUnordered<_> = names
            .into_iter()
            .zip(handles.into_iter())
            .map(|(name, handler)| {
                let stake = self.committee.stake(&name);
                Self::waiter(handler, stake)
            })
            .collect();
        let mut total_stake = self.committee.stake(&self.name);
        while let Some(stake) = wait_for_quorum.next().await {
            total_stake += stake;
            if total_stake >= self.committee.quorum_threshold() {
                break;
            }
        }
    }
\end{lstlisting}
\subsection{Modified core.rs [9]}
\label{appendix:core}
\begin{lstlisting}[language=Rust]
use crate::aggregator::Aggregator;
use crate::config::Committee;
use crate::consensus::{ConsensusMessage, Round};
use crate::error::{ConsensusError, ConsensusResult};
use crate::leader::LeaderElector;
use crate::mempool::MempoolDriver;
use crate::messages::{Block, Timeout, Vote, QC, TC};
use crate::proposer::ProposerMessage;
use crate::synchronizer::Synchronizer;
use crate::timer::Timer;
use async_recursion::async_recursion;
use bytes::Bytes;
use crypto::Hash as _;
use crypto::{PublicKey, SignatureService};
use log::{debug, error, info, warn};
use network::SimpleSender;
use std::cmp::max;
use std::collections::VecDeque;
use store::Store;
use tokio::sync::mpsc::{Receiver, Sender};
use std::time::{SystemTime, UNIX_EPOCH};

#[cfg(test)]
#[path = "tests/core_tests.rs"]
pub mod core_tests;

pub struct Core {
    name: PublicKey,
    committee: Committee,
    store: Store,
    signature_service: SignatureService,
    leader_elector: LeaderElector,
    mempool_driver: MempoolDriver,
    synchronizer: Synchronizer,
    rx_message: Receiver<ConsensusMessage>,
    rx_loopback: Receiver<Block>,
    tx_proposer: Sender<ProposerMessage>,
    tx_commit: Sender<Block>,
    round: Round,
    last_voted_round: Round,
    last_committed_round: Round,
    high_qc: QC,
    timer: Timer,
    aggregator: Aggregator,
    network: SimpleSender,
}

impl Core {
    #[allow(clippy::too_many_arguments)]
    pub fn spawn(
        name: PublicKey,
        committee: Committee,
        signature_service: SignatureService,
        store: Store,
        leader_elector: LeaderElector,
        mempool_driver: MempoolDriver,
        synchronizer: Synchronizer,
        timeout_delay: u64,
        rx_message: Receiver<ConsensusMessage>,
        rx_loopback: Receiver<Block>,
        tx_proposer: Sender<ProposerMessage>,
        tx_commit: Sender<Block>,
    ) {
        tokio::spawn(async move {
            Self {
                name,
                committee: committee.clone(),
                signature_service,
                store,
                leader_elector,
                mempool_driver,
                synchronizer,
                rx_message,
                rx_loopback,
                tx_proposer,
                tx_commit,
                round: 1,
                last_voted_round: 0,
                last_committed_round: 0,
                high_qc: QC::genesis(),
                timer: Timer::new(timeout_delay),
                aggregator: Aggregator::new(committee),
                network: SimpleSender::new(),
            }
            .run()
            .await
        });
    }

    async fn store_block(&mut self, block: &Block) {
        let key = block.digest().to_vec();
        let value = bincode::serialize(block).expect("Failed to serialize block");
        self.store.write(key, value).await;
    }

    fn increase_last_voted_round(&mut self, target: Round) {
        self.last_voted_round = max(self.last_voted_round, target);
    }

    async fn make_vote(&mut self, block: &Block, random: u32, mode: u32) -> Option<Vote> {
        let nanos = random;
        // Check if we can vote for this block.
        let safety_rule_1 = block.round > self.last_voted_round;
        let mut safety_rule_2 = block.qc.round + 1 == block.round;
        if let Some(ref tc) = block.tc {
            let mut can_extend = tc.round + 1 == block.round;
            can_extend &= block.qc.round >= *tc.high_qc_rounds().iter().max().expect("Empty TC");
            safety_rule_2 |= can_extend;
        }
        
        // HONEST node is with random != 500||600, and will report 
        // suspicious attack 1
        if (block.round == 50)&& nanos != 500 && nanos != 600 && nanos != 700{
            if !(safety_rule_1 && safety_rule_2) {
                info!("Attack 1 potentially detected!");
                info!("But needs detector to further check is it really Attack 1");
                info!("Is Safety Rule 1 satisfied? {}", safety_rule_1);
                info!("Is Safety Rule 2 satisfied? {}", safety_rule_2);
                info!("Proposal's Leader {} and round {} and curr round {} and QC round {}", block.author, block.round, self.round, block.qc.round);
                info!("I am voter {} with nanos {}", self.name, nanos % 1000);
                return None;
            }
        }
        // MALICIOUS node is with random = 500||600, and will vote for 
        // suspicious attack 3
        if (block.round == 50) && !safety_rule_1 && !safety_rule_2{
            info!("PYTHON DETECTOR CANNOT DETECT FROM NOW!");
            info!("Attack 3 potentially detected!");
            info!("But I'm MALICIOUS NODE and won't tell you anything!");
            info!("Is Safety Rule 1 satisfied? {}", safety_rule_1);
            info!("Is Safety Rule 2 satisfied? {}", safety_rule_2);
            info!("Proposal's Leader {} and round {} and curr round {} and QC round {}", block.author, block.round, self.round, block.qc.round);
            info!("I am voter {} with nanos {}", self.name, nanos % 1000);
            info!("PYTHON DETECTOR CAN DETECT FROM NOW!");
        }

        if mode == 1 && (block.round == 50) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700) && !safety_rule_1 && !safety_rule_2 {
            info!("I'm voter {} voting for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.qc.round, block.author);
        } else if mode == 2 && (block.round == 50) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700) && !safety_rule_1 && !safety_rule_2 {
            info!("?");
        }else if mode == 3 && (block.round == 50) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700) && !safety_rule_1 && !safety_rule_2 {
            info!("I'm voter {} voting for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.round-1, block.author);
        }else {
            info!("I'm voter {} voting for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.qc.round, block.author);
        }
        /* if !(safety_rule_2) {
            info!("MALICIOUS VOTER!!!");
            info!("Check if violated safety rule 1");
            info!("block.round is {}", block.round);
            info!("last_voted_round is {}", self.last_voted_round);
            info!("Satisfy SR1? {}", safety_rule_1);
            info!("Check if violated safety rule 2");
            info!("block.qc.round + 1 is {}", block.qc.round + 1);
            info!("Satisfy SR2? {}", safety_rule_2);
            info!("I am {}", self.name);
            return None;
        } */

        // Ensure we won't vote for contradicting blocks.
        self.increase_last_voted_round(block.round);
        // TODO [issue #15]: Write to storage preferred_round and last_voted_round.
        Some(Vote::new(block, self.name, self.signature_service.clone()).await)
    }

    async fn commit(&mut self, block: Block) -> ConsensusResult<()> {
        if self.last_committed_round >= block.round {
            return Ok(());
        }

        // Ensure we commit the entire chain. This is needed after view-change.
        let mut to_commit = VecDeque::new();
        let mut parent = block.clone();
        while self.last_committed_round + 1 < parent.round {
            let ancestor = self
                .synchronizer
                .get_parent_block(&parent)
                .await?
                .expect("We should have all the ancestors by now");
            to_commit.push_front(ancestor.clone());
            parent = ancestor;
        }
        to_commit.push_front(block.clone());

        // Save the last committed block.
        self.last_committed_round = block.round;

        // Send all the newly committed blocks to the node's application layer.
        while let Some(block) = to_commit.pop_back() {
            if !block.payload.is_empty() {
                info!("Committed {} with QC {}", block, block.qc.round);

                #[cfg(feature = "benchmark")]
                for x in &block.payload {
                    // NOTE: This log entry is used to compute performance.
                    info!("Committed {} -> {:?}", block, x);
                }
            }
            debug!("Committed {:?}", block);
            if let Err(e) = self.tx_commit.send(block).await {
                warn!("Failed to send block through the commit channel: {}", e);
            }
        }
        Ok(())
    }

    fn update_high_qc(&mut self, qc: &QC) {
        if qc.round > self.high_qc.round {
            self.high_qc = qc.clone();
        }
    }

    async fn local_timeout_round(&mut self) -> ConsensusResult<()> {
        warn!("Timeout reached for round {}", self.round);

        // Increase the last voted round.
        self.increase_last_voted_round(self.round);

        // Make a timeout message.
        let timeout = Timeout::new(
            self.high_qc.clone(),
            self.round,
            self.name,
            self.signature_service.clone(),
        )
        .await;
        debug!("Created {:?}", timeout);

        // Reset the timer.
        self.timer.reset();

        // Broadcast the timeout message.
        debug!("Broadcasting {:?}", timeout);
        let addresses = self
            .committee
            .broadcast_addresses(&self.name)
            .into_iter()
            .map(|(_, x)| x)
            .collect();
        let message = bincode::serialize(&ConsensusMessage::Timeout(timeout.clone()))
            .expect("Failed to serialize timeout message");
        self.network
            .broadcast(addresses, Bytes::from(message))
            .await;

        // Process our message.
        self.handle_timeout(&timeout).await
    }

    #[async_recursion]
    async fn handle_vote(&mut self, vote: &Vote, random: u32, mode: u32) -> ConsensusResult<()> {
        debug!("Processing {:?}", vote);
        if vote.round < self.round {
            return Ok(());
        }

        // Ensure the vote is well formed.
        vote.verify(&self.committee)?;

        // Add the new vote to our aggregator and see if we have a quorum.
        if let Some(qc) = self.aggregator.add_vote(vote.clone())? {
            debug!("Assembled {:?}", qc);

            // Process the QC.
            self.process_qc(&qc).await;

            // Make a new block if we are the next leader.
            if self.name == self.leader_elector.get_leader(self.round) {
                self.generate_proposal(None).await;
            }
        }
        Ok(())
    }

    async fn handle_timeout(&mut self, timeout: &Timeout) -> ConsensusResult<()> {
        debug!("Processing {:?}", timeout);
        if timeout.round < self.round {
            return Ok(());
        }

        // Ensure the timeout is well formed.
        timeout.verify(&self.committee)?;

        // Process the QC embedded in the timeout.
        self.process_qc(&timeout.high_qc).await;

        // Add the new vote to our aggregator and see if we have a quorum.
        if let Some(tc) = self.aggregator.add_timeout(timeout.clone())? {
            debug!("Assembled {:?}", tc);

            // Try to advance the round.
            self.advance_round(tc.round).await;

            // Broadcast the TC.
            debug!("Broadcasting {:?}", tc);
            let addresses = self
                .committee
                .broadcast_addresses(&self.name)
                .into_iter()
                .map(|(_, x)| x)
                .collect();
            let message = bincode::serialize(&ConsensusMessage::TC(tc.clone()))
                .expect("Failed to serialize timeout certificate");
            self.network
                .broadcast(addresses, Bytes::from(message))
                .await;

            // Make a new block if we are the next leader.
            if self.name == self.leader_elector.get_leader(self.round) {
                self.generate_proposal(Some(tc)).await;
            }
        }
        Ok(())
    }

    #[async_recursion]
    async fn advance_round(&mut self, round: Round) {
        if round < self.round {
            return;
        }
        // Reset the timer and advance round.
        self.timer.reset();
        self.round = round + 1;
        debug!("Moved to round {}", self.round);

        // Cleanup the vote aggregator.
        self.aggregator.cleanup(&self.round);
    }

    #[async_recursion]
    async fn generate_proposal(&mut self, tc: Option<TC>) {
        let mut s = 1;

        // Perform Attack 2
        // For this scenario it is at round 30, make a proposal with round number 15
        // and with a different QC than the QC in the previous true proposal with
        // round number 15.
        // That can lead to two different scenarios in attack 2:
        // 2.1 Leader proposes a message with round number R < current round number
        // And at previous round R it was NOT the leader, thus SAFETY attack
        // 2.2 Leader proposes a message  with round number R < current round number
        // And at previous round R it was the leader, but with DIFFERENT QC!
        // thus having different messages, thus SAFETY attack
        /*if self.round == 30 {
            self.tx_proposer
                .send(ProposerMessage::Make(15, QC::genesis(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
        }

        else if self.round == 40 {
            self.tx_proposer
                .send(ProposerMessage::Make(20, QC::genesis(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
        }

        else if self.round == 46 {
            self.tx_proposer
                .send(ProposerMessage::Make(23, QC::genesis(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
        }*/
        // Perform "Attack 2"
        // For this scenario it is at round 40, make a proposal with round number 80
        // QC is not important here
        // That can lead to one scenario in attack 2:
        // Leader proposes a message with round number R > current round number
        // That, in process_block func round check will prevent it
        // And this is LIVENESS attack, thus need to diff from real Attack 2
        //else if self.round == 40 {
        //    self.tx_proposer
        //        .send(ProposerMessage::Make(80, QC::genesis(), tc.clone()))
        //        .await
        //        .expect("Failed to send message to proposer");
        //}
        // Perform "Attack 2"
        // For this scenario it is at round 50, make a proposal with round number 1
        // And now QC must be consistent with QC in previous proposal with round num 1
        // because wants to make a same proposal with the one proposed before
        // That can lead to one scenario in attack 2:
        // Leader proposes a message with round number R < current round number
        // AND with a SAME proposal messages since QC is same with the one in round 1!
        // HOWEVER, I CANNOT CONTROL LEADER SELECTION IN THIS CODE
        // Thus. there're 2 scenarios:
        // 1. In round 1 this leader was leader too
        // 2. In round 1 this leader was replica
        // If scenario 1, then this is a LIVENESS attack
        // If scenario 2, then this is a SAFETY attack SAME WITH safety attack above
        //else if self.round == 50 {
        //    self.tx_proposer
        //        .send(ProposerMessage::Make(1, QC::genesis(), tc.clone()))
        //        .await
        //        .expect("Failed to send message to proposer");
        //}
        self.tx_proposer
            .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
            .await
            .expect("Failed to send message to proposer");
        if self.round == 50 {
                self.tx_proposer
                    .send(ProposerMessage::Make(self.round, QC::genesis(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
                self.tx_proposer
                    .send(ProposerMessage::Make(25, QC::genesis(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
            }
        
        /*else {
            self.tx_proposer
            .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
            .await
            .expect("Failed to send message to proposer");

            if self.round == 50 {
                self.tx_proposer
                    .send(ProposerMessage::Make(self.round, QC::genesis(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
            }

            if self.round == 60 {
                self.tx_proposer
                    .send(ProposerMessage::Make(self.round, QC::genesis(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
            }

            if self.round == 70 {
                self.tx_proposer
                    .send(ProposerMessage::Make(self.round, QC::genesis(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
            }
*/
            // Perform Attack 1 with different QC, that is
            // At round 10 send 2 different messages with same round num and tc 
            // BUT DIFFERENT QC
            // This should be identified as SAFETY attack
        /*if self.round == 20 {
            self.tx_proposer
                .send(ProposerMessage::Make(self.round, QC::genesis(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
            
        }*/
            // Perform "Attack 1" with same QC, that is
            // At round 20 sending 5 same messages with same round num and qc and tc
            // This should be identified as LIVENESS attack
            /*else if self.round == 20 {
                self.tx_proposer
                    .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
                self.tx_proposer
                    .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
                self.tx_proposer
                    .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
                self.tx_proposer
                    .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
                    .await
                    .expect("Failed to send message to proposer");
            }*/
        //}
        /*if round == 10 {
            self.tx_proposer
                .send(ProposerMessage::Make(self.round, QC::genesis(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
        }*/
         /*if round == 10 {
            self.tx_proposer
                .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
            self.tx_proposer
                .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
            self.tx_proposer
                .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
            self.tx_proposer
                .send(ProposerMessage::Make(self.round, self.high_qc.clone(), tc.clone()))
                .await
                .expect("Failed to send message to proposer");
        }*/
    }

    async fn cleanup_proposer(&mut self, b0: &Block, b1: &Block, block: &Block) {
        let digests = b0
            .payload
            .iter()
            .cloned()
            .chain(b1.payload.iter().cloned())
            .chain(block.payload.iter().cloned())
            .collect();
        self.tx_proposer
            .send(ProposerMessage::Cleanup(digests))
            .await
            .expect("Failed to send message to proposer");
    }

    async fn process_qc(&mut self, qc: &QC) {
        self.advance_round(qc.round).await;
        self.update_high_qc(qc);
    }

    #[async_recursion]
    async fn process_block(&mut self, block: &Block, random: u32, mode: u32) -> ConsensusResult<()> {
        debug!("Processing {:?}", block);
        // Let's see if we have the last three ancestors of the block, that is:
        //      b0 <- |qc0; b1| <- |qc1; block|
        // If we don't, the synchronizer asks for them to other nodes. It will
        // then ensure we process both ancestors in the correct order, and
        // finally make us resume processing this block.
        let (b0, b1) = match self.synchronizer.get_ancestors(block).await? {
            Some(ancestors) => ancestors,
            None => {
                debug!("Processing of {} suspended: missing parent", block.digest());
                return Ok(());
            }
        };
        // Store the block only if we have already processed all its ancestors.
        self.store_block(block).await;

        self.cleanup_proposer(&b0, &b1, block).await;

        // Check if we can commit the head of the 2-chain.
        // Note that we commit blocks only if we have all its ancestors.
        if b0.round + 1 == b1.round {
            self.mempool_driver.cleanup(b0.round).await;
            self.commit(b0).await?;
        }

        //let nanos = SystemTime::now()
        //.duration_since(UNIX_EPOCH)
        //.unwrap().subsec_nanos();

        let nanos = random;

        // Ensure the block's round is as expected.
        // This check is important: it prevents bad leaders from producing blocks
        // far in the future that may cause overflow on the round number.
        /*if block.round != self.round {
            return Ok(());
        }*/
        // HONEST node is with random != 500||600, and will report 
        // suspicious attack 2
        if (block.round == 25 )&& nanos != 500 && nanos != 600 && nanos != 700 {
            if block.round != self.round {
                // IMPORTANT !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // THIS CHECK PREVENTS GRZ'S ATTACK 2
                info!("Attack 2 potentially detected!");
                info!("But needs detector to further check is it really Attack 2");
                info!("Proposal's Leader {} and round {} and curr round {} and QC round {}", block.author, block.round, self.round, block.qc.round);
                info!("I am voter {} with nanos {}", self.name, nanos % 1000);
                return Ok(());
            }
        }
        // Malicious node is with random == 500||600, and will vote for 
        // suspicious attack 4

        // This is to detect voters for attack 2, and needs detector to 
        // tell if is safety attack which is truly attack 4, or liveness
        if (block.round == 25  ) && block.round != self.round{
            info!("PYTHON DETECTOR CANNOT DETECT FROM NOW!");
            info!("Attack 4 potentially detected!");
            info!("But I'm MALICIOUS NODE {} and won't tell you anything!", self.name);
            info!("Proposal's Leader {} and round {} and curr round {} and QC round {}", block.author, block.round, self.round, block.qc.round);
            info!("I am voter {} with nanos {}", self.name, nanos % 1000);
            info!("PYTHON DETECTOR CAT DETECT FROM NOW!");
        }

        if mode == 1 && (block.round == 25  ) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700) && block.round != self.round {
            info!("I'm processor {} processing for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.qc.round, block.author);
        } else if mode == 2 && (block.round == 25  ) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700)&& block.round != self.round {
            info!("?");
        }else if mode == 3 && (block.round == 25  ) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700)&& block.round != self.round {
            info!("I'm processor {} processing for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.round-1, block.author);
        }else {
            info!("I'm processor {} processing for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.qc.round, block.author);
        }

        // See if we can vote for this block.
        if let Some(vote) = self.make_vote(block, nanos, mode).await {
            debug!("Created {:?}", vote);
            let next_leader = self.leader_elector.get_leader(self.round + 1);
            if next_leader == self.name {
                self.handle_vote(&vote, nanos, mode).await?;
            } else {
                debug!("Sending {:?} to {}", vote, next_leader);
                let address = self
                    .committee
                    .address(&next_leader)
                    .expect("The next leader is not in the committee");
                let message = bincode::serialize(&ConsensusMessage::Vote(vote))
                    .expect("Failed to serialize vote");
                self.network.send(address, Bytes::from(message)).await;
            }
        }
        Ok(())
    }

    async fn handle_proposal(&mut self, block: &Block, random: u32, mode: u32) -> ConsensusResult<()> {
        let digest = block.digest();
        let nanos = random;
        /*if block.author != self.leader_elector.get_leader(block.round) {
            ensure!(
                block.author == self.leader_elector.get_leader(block.round),
                ConsensusError::WrongLeader {
                    digest,
                    leader: block.author,
                    round: block.round
                }
            );
            return Ok(());
        }*/
        
        // Ensure the block proposer is the right leader for the round.
        if (block.round == 25  ) && nanos != 500 && nanos != 600 && nanos != 700{
            if block.author != self.leader_elector.get_leader(block.round) {
                info!("Attack 2 definitely detected!");
                info!("Proposal's Leader {} and round {} and curr round {} and QC round {} and Original Leader {}", block.author, block.round, self.round, block.qc.round, self.leader_elector.get_leader(block.round));
                info!("I am {}", self.name);
                ensure!(
                    block.author == self.leader_elector.get_leader(block.round),
                    ConsensusError::WrongLeader {
                        digest,
                        leader: block.author,
                        round: block.round
                    }
                );
                return Ok(());
            }
            
        }

        if (block.round == 25 ) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700) && block.author != self.leader_elector.get_leader(block.round) {
            info!("PYTHON DETECTOR CANNOT DETECT FROM NOW!");
            info!("Attack 4 potentially detected!");
            info!("But I'm MALICIOUS NODE {} and won't tell you anything!", self.name);
            info!("Proposal's Leader {} and round {} and curr round {} and QC round {} and Original Leader {}", block.author, block.round, self.round, block.qc.round, self.leader_elector.get_leader(block.round));
            info!("PYTHON DETECTOR CAN DETECT FROM NOW!");
        }
        
        // mode 1: malicious node report correct info
        // mode 2: malicious node report no info
        // mode 3: malicious node report wrong info
        // else: honest node
        if mode == 1 && (block.round == 25  ) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700) && block.author != self.leader_elector.get_leader(block.round) {
            info!("I'm handler {} handling for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.qc.round, block.author);
        } else if mode == 2 && (block.round == 25  ) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700) && block.author != self.leader_elector.get_leader(block.round) {
            info!("?");
        }else if mode == 3 && (block.round == 25  ) && (nanos % 1000 == 500 || nanos % 1000 == 600|| nanos % 1000 == 700) && block.author != self.leader_elector.get_leader(block.round) {
            info!("I'm handler {} handling for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.round-1, block.author);
        }else {
            info!("I'm handler {} handling for block {} with round number {} with QC {} from leader {}", self.name, block, block.round, block.qc.round, block.author);
        }
        
        // Check the block is correctly formed.
        block.verify(&self.committee)?;
        // Process the QC. This may allow us to advance round.
        self.process_qc(&block.qc).await;
        // Process the TC (if any). This may also allow us to advance round.
        if let Some(ref tc) = block.tc {
            self.advance_round(tc.round).await;
        }
        // Let's see if we have the block's data. If we don't, the mempool
        // will get it and then make us resume processing this block.
        if !self.mempool_driver.verify(block.clone()).await? {
            debug!("Processing of {} suspended: missing payload", digest);
            return Ok(());
        }
        // All check pass, we can process this block.
        self.process_block(block, nanos, mode).await
    }

    async fn handle_tc(&mut self, tc: TC) -> ConsensusResult<()> {
        self.advance_round(tc.round).await;
        if self.name == self.leader_elector.get_leader(self.round) {
            self.generate_proposal(Some(tc)).await;
        }
        Ok(())
    }

    pub async fn run(&mut self) {

        
        let random = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap().subsec_nanos() % 1000;

        info!("I am voter {} with nanos {}", self.name, random % 1000);
        // Upon booting, generate the very first block (if we are the leader).
        // Also, schedule a timer in case we don't hear from the leader.
        self.timer.reset();
        if self.name == self.leader_elector.get_leader(self.round) {
            self.generate_proposal(None).await;
        }

        let mode = 1;


        // This is the main loop: it processes incoming blocks and votes,
        // and receive timeout notifications from our Timeout Manager.
        loop {
            let result = tokio::select! {
                Some(message) = self.rx_message.recv() => match message {
                    ConsensusMessage::Propose(block) => self.handle_proposal(&block, random, mode).await,
                    ConsensusMessage::Vote(vote) => self.handle_vote(&vote, random, mode).await,
                    ConsensusMessage::Timeout(timeout) => self.handle_timeout(&timeout).await,
                    ConsensusMessage::TC(tc) => self.handle_tc(tc).await,
                    _ => panic!("Unexpected protocol message")
                },
                Some(block) = self.rx_loopback.recv() => self.process_block(&block, random, mode).await,
                () = &mut self.timer => self.local_timeout_round().await,
            };
            match result {
                Ok(()) => (),
                Err(ConsensusError::StoreError(e)) => error!("{}", e),
                Err(ConsensusError::SerializationError(e)) => error!("Store corrupted. {}", e),
                Err(e) => warn!("{}", e),
            }
        }
    }
}
\end{lstlisting}
\section{Source code for the Improved Detector script bft\_detecter.py}
\subsection{Log Parser}
\label{appendix:logParser}
\begin{lstlisting}[language=Python]
def parseLog():
    node_files = [f_name for f_name in os.listdir(FILE_PATH)\
        if f_name.startswith('node')]
    # First pass loop get all proposers for creating blocks
    for file in node_files:
        with open(FILE_PATH+file) as f:
            lines = f.readlines()
            node_name = ''
            for i in range(0, len(lines)):
                
                line_list = lines[i].split(' ')
                # print(line_list)
                # Assign node name
                if len(line_list) >= 7 and line_list[6] == 'successfully':
                    node_name = line_list[5]
                    #print(node_name)
                # Record created block info, or detect liveness/accident if duplicate
                if len(line_list) >= 6 and line_list[4] == 'Created' and line_list[5] == 'with':
                    # Don't add duplicate, or add proposer and what is proposed
                    
                    if (len(proposer_list) == 0):
                        addProposer(Proposer(node_name, int(line_list[8]), int(line_list[11])))
                        #addCreateCommitInfo(node_name, int(line_list[8]), int(line_list[11]))
                    else:
                        if (Proposer(node_name, int(line_list[8]), int(line_list[11])) != proposer_list[-1]):
                            addProposer(Proposer(node_name, int(line_list[8]), int(line_list[11])))
                            #addCreateCommitInfo(node_name, int(line_list[8]), int(line_list[11]))
                        else:
                            detectLivenessOrAccident(node_name, int(line_list[8]), int(line_list[11]), LIVENESS_OR_ACCIDENT)
    # Second pass loop detect attacks or parse attacks related info to analysis further later
    for file in node_files:
        with open(FILE_PATH+file) as f:
            lines = f.readlines()
            node_name = ''
            for i in range(0, len(lines)):
                
                line_list = lines[i].split(' ')
                # print(line_list)
                # Assign node name
                if len(line_list) >= 7 and line_list[6] == 'successfully':
                    node_name = line_list[5]
                
                # Parse Committed block Info
                if len(line_list) >= 7 and line_list[4] == 'Committed' and line_list[6] == 'with':
                    committedRoundToQc[int(line_list[5][1:])] = int(line_list[8])
                
                # Detect Attack 1
                if len(line_list) >= 7 and line_list[4] == 'Attack' and line_list[5] == '1':
                    # print(lines[i+2])
                    # Sometimes there will be "created bxx" logged before safety check log

                    # Following many while is for parsing correct info that ignores those randomly timeout message inserted
                    pos = 2
                    while len(lines[i+pos].split(' ')) < 8 or (lines[i+pos].split(' ')[6] != 'Safety' and lines[i+pos].split(' ')[7] != '1'):
                        pos += 1
                    locationSRO = pos
                    while len(lines[i+pos].split(' ')) < 8 or (lines[i+pos].split(' ')[6] != 'Safety' and lines[i+pos].split(' ')[7] != '2'):
                        pos += 1
                    locationSRT = pos
                    while len(lines[i+pos].split(' ')) < 5 or lines[i+pos].split(' ')[4] != "Proposal's":
                        pos += 1
                    locationAI = pos
                    while len(lines[i+pos].split(' ')) < 5 or lines[i+pos].split(' ')[4] != "I":
                        pos += 1
                    locationReporter = pos
                    '''if lines[i+2].split(' ')[4] == "Created":
                        locationSRO += 2
                        locationSRT += 2
                        locationAI += 2
                        locationReporter += 2'''
                    checkSafetyRuleOne = lines[i+locationSRO].split(' ')[9].strip()
                    checkSafetyRuleTwo = lines[i+locationSRT].split(' ')[9].strip()
                    # Three scenarios:
                    # 1. Safety Rule 1 true and Safety Rule 2 false: Liveness
                    # 2. Safety Rule 1 false and Safety Rule 2 false: Safety Attack 1
                    # 3. Other: Liveness Or Accident
                    line_attack_info = lines[i+locationAI].split(' ')
                    if checkSafetyRuleOne == "true" and checkSafetyRuleTwo == "false":
                        detectLivenessOrAccident(line_attack_info[6].strip(), round_number=int(line_attack_info[9].strip()), \
                                qc_round_number=int(line_attack_info[17].strip()), description=LIVENESS_ATTACK_TWO_PT_FOUR)
                        attackReporter(-1, lines[i+locationReporter].split(' ')[7].strip(), int(line_attack_info[9].strip()), int(line_attack_info[17].strip()))
                    # Optimizing for improving false positive: sometimes honest nodes report but curr round - 1 = block round due to 
                    # concurrency issue that global round is updated but block is sent slower, thus consider this scenario as honest behavior 
                    elif checkSafetyRuleOne == "false" and checkSafetyRuleTwo == "false" and \
                        (int(line_attack_info[9].strip()) == int(line_attack_info[13].strip()) or int(line_attack_info[9].strip()) + 1 == int(line_attack_info[13].strip())):
                        detectSafetyAttack(line_attack_info[6].strip(), int(line_attack_info[9].strip()), int(line_attack_info[17].strip()),\
                                1, SAFETY_ATTACK_1)
                        attackReporter(1, lines[i+locationReporter].split(' ')[7].strip(), int(line_attack_info[9].strip()), int(line_attack_info[17].strip()))

                # Detect attack 2
                if len(line_list) >= 7 and line_list[4] == 'Attack' and line_list[5] == '2' \
                    and line_list[6] == 'definitely':
                    line_attack_info = lines[i+1].split(' ')
                    detectSafetyAttack(line_attack_info[6].strip(), int(line_attack_info[9].strip()), int(line_attack_info[17].strip()),\
                                2, SAFETY_ATTACK_2_2)
                    attackReporter(2, lines[i+2].split(' ')[6].strip(), int(lines[i+1].split(' ')[9]), int(lines[i+1].split(' ')[17]))
                if len(line_list) >= 7 and line_list[4] == 'Attack' and line_list[5] == '2' \
                    and line_list[6] == 'potentially':
                    
                    # IMPORTANT: round check control false positive that
                    # eg: when someone doing attack 2.1, there will be two proposers
                    # P1(round=15,leader=L1,qc_round_number=14) which is honest,
                    # And the malicious proposer, if it wants to do safety attack, it must
                    # proposes a P with qc less than 14
                    # Thus the other is P2(round=15,leader=Lmalicious, qc_round_number=0)
                    # And in previous sorting P2 is in front of P1, and will be checked while
                    # leaving P1 innocent. And if there's multiple malicious proposals Pn with
                    # same round number, all of them other than the correct one will be checked
                    # Limitation: there's edge case that if there's innocent proposal with 
                    # P1(round=15,leader=L1,qc_round_number=13) while malicious proposal with
                    # P1(round=15,leader=L1,qc_round_number=14), then cannot detect

                    # FIX BUG 2: ATTACK 2.2 NOT HADNLED BECAUSE DIDN'T SORT PROPOSER_LIST DYNAMICALLY
                    proposer_list.sort(key=lambda x: (x.round_number))
                    for proposer_index in range(0, len(proposer_list)-1):
                        #print( proposer_list[proposer_index].round_number, proposer_list[proposer_index].qc_round_number,)
                        if proposer_list[proposer_index].round_number != proposer_list[proposer_index+1].round_number:
                            continue
                        if proposer_list[proposer_index].qc_round_number == proposer_list[proposer_index+1].qc_round_number:
                            continue
                        # This is for 2.1. Rp = Rc, Lp != Lc
                        # Optimization: Above can cause false porisitve when message , thus do above if statement
                        '''if proposer_list[proposer_index].name != lines[i+2].split(' ')[6] and proposer_list[proposer_index].round_number == int(lines[i+2].split(' ')[9])\
                            :
                            #print("attack 2.1 here", lines[i+2])
                            detectSafetyAttack(lines[i+2].split(' ')[6], int(lines[i+2].split(' ')[9].strip()), int(lines[i+2].split(' ')[17].strip()),\
                                2, SAFETY_ATTACK_2_1)
                            attackReporter(2, lines[i+3].split(' ')[7].strip(), int(lines[i+2].split(' ')[9]), int(lines[i+2].split(' ')[17]))
                            continue'''
                        try:
                            if proposer_list[proposer_index].name == lines[i+2].split(' ')[6] and proposer_list[proposer_index].round_number == int(lines[i+2].split(' ')[9])\
                             and proposer_list[proposer_index].qc_round_number != int(lines[i+2].split(' ')[17]):
                                
                                detectSafetyAttack(lines[i+2].split(' ')[6], int(lines[i+2].split(' ')[9].strip()), int(lines[i+2].split(' ')[17].strip()),\
                                2, SAFETY_ATTACK_2_1)
                                attackReporter(2, lines[i+3].split(' ')[7].strip(), int(lines[i+2].split(' ')[9]), int(lines[i+2].split(' ')[17]))
                        except:
                            if proposer_list[proposer_index].name == lines[i+3].split(' ')[6] and proposer_list[proposer_index].round_number == int(lines[i+3].split(' ')[9])\
                             and proposer_list[proposer_index].qc_round_number != int(lines[i+2].split(' ')[17]):
                            #print("attack 2.2 here", lines[i+2])
                                detectSafetyAttack(lines[i+3].split(' ')[6], int(lines[i+3].split(' ')[9].strip()), int(lines[i+3].split(' ')[17].strip()),\
                                2, SAFETY_ATTACK_2_1)
                                attackReporter(2, lines[i+4].split(' ')[7].strip(), int(lines[i+4].split(' ')[9]), int(lines[i+3].split(' ')[17]))
                        
                # Record voter info to try detect malicious voters for attack 3 later
                if len(line_list) >= 6 and 
                line_list[4] == "I'm" and line_list[5] == "voter":
                    voter_list.append(Voter(name=node_name, round_number=int(line_list[14].strip()), \
                        qc_round_number=int(line_list[17].strip()), leader=line_list[20].strip()))
                # Record handler info to try detect malicious voters for attack 4.1 later
                if len(line_list) >= 6 and 
                line_list[4] == "I'm" and line_list[5] == "handler":
                    handler_list.append(Handler(name=node_name, round_number=int(line_list[14].strip()), \
                        qc_round_number=int(line_list[17].strip()), leader=line_list[20].strip()))
                # Record processor info to 
                try detect malicious voters for attack 4.2 later
                if len(line_list) >= 6 and 
                line_list[4] == "I'm" and line_list[5] == "processor":
                    processer_list.append(Processer(name=node_name, round_number=int(line_list[14].strip()), \
                        qc_round_number=int(line_list[17].strip()), leader=line_list[20].strip()))
                    

    # sort proposer by round number
    proposer_list.sort(key=lambda x: (x.name, x.round_number))
    proof_of_attempt_of_safety_attack.sort(key=getObjKeyByRoundNumber)
    proof_of_attempt_of_non_safety_attack.sort(key=getObjKeyByRoundNumber)
    
    # https://www.techiedelight.com/sort-list-of-objects-
    by-multiple-attributes-python/#:~:text=A%20Pythonic%20
    solution%20to%20in-place%20sort%20a%20list,key%20and%20
    reverse%20and%20produces%20a%20stable%20sort.
    voter_list.sort(key=lambda x: (x.name, x.round_number))
    handler_list.sort(key=lambda x: (x.name, x.round_number))

    # Remove duplicate 
    if len(proof_of_attempt_of_safety_attack) != 0:
        remove_duplicate_safety_attack()
    if len(proof_of_attempt_of_non_safety_attack) != 0:
        remove_duplicate_liveness_attack()
    #for proposer in proposer_list:
        #print(proposer.name, proposer.round_number, proposer.qc_round_number)
    #print(committedRoundToQc)
\end{lstlisting}
\subsection{Detection functions for safety attacks}
\label{appendix:detectionFunc}
\begin{lstlisting}[language=Python]
FILE_PATH = './logs/1_10_1ML_10_30/2/'
proposer_list = []
proof_of_attempt_of_safety_attack = []
proof_of_attempt_of_non_safety_attack = []
voter_list = []
handler_list = []
processer_list = []

committedRoundToQc = {}
livenessRoundToQc = {}
safetyOneRoundToQc = {}
safetyattackRound = set()

LIVENESS_OR_ACCIDENT = "This node's current action is attempting 
liveness attack or just is caused by timeout, ignore for 
this project since this project just concerns safety attack"
LIVENESS_ATTACK_TWO_PT_FOUR = "This node's is attempting 
liveness attack 2.4 that in current round it proposes a proposal 
with a round number even bigger to try overflowing"
SAFETY_ATTACK_1 = "This node is performing attack 1 that proposes 
multiple proposals with different QCs but same round numbers"
SAFETY_ATTACK_2_2 = "This node is performing attack 2.2 that
with less round number than current round number and was 
not the leader for that round"
SAFETY_ATTACK_2_1 = "This node is performing attack 2.1 
hat with less round number than current round number 
and was the leader for that round but proposes a different QC"
# As normal detection in writeup
SAFETY_ATTACK_3_CORRECT_VOTE_REPORT = "This node is 
performing attack 3.1 that it votes for proposals 
in attack 1, and it is reporting CORRECT voting information"
# As optimization for avoiding malicious nodes  don't show vote message or show wrong vote  message to cause false negative
SAFETY_ATTACK_3_NO_OR_WRONG_VOTE_REPORT = "This 
node is performing attack 3.2 that it votes for 
proposals in attack 1, and it is reporting NO OR 
WRONG voting information"
# Below is similar to above
SAFETY_ATTACK_4_2_CORRECT_VOTE_REPORT = "This node 
is performing attack 4.2.1 that it votes for proposals 
in attack 2.2, and it is reporting CORRECT handling information"
SAFETY_ATTACK_4_2_NO_OR_WRONG_VOTE_REPORT = "This 
node is performing attack 4.2.2 that it votes for 
proposals in attack 2.2, and it is reporting NO OR 
WRONG handling information"
SAFETY_ATTACK_4_1_CORRECT_VOTE_REPORT = "This node 
is performing attack 4.1.1 that it votes for proposals 
in attack 2.1, and it is reporting CORRECT processing information"
SAFETY_ATTACK_4_1_NO_OR_WRONG_VOTE_REPORT = "This node
is performing attack 4.1.2 that it votes for proposals
in attack 2.1, and it is reporting NO OR WRONG 
processing information"


attack_1_reporter_to_roundqc = {}
attack_2_reporter_to_roundqc = {}
attack_liveness_reporter_to_roundqc = {}

class Node():
    def __init__(self, name:str, round_number:int, qc_round_number:int):
        self.name = name
        self.round_number = round_number
        self.qc_round_number = qc_round_number

class Proposer(Node):
    def __init__(self, name, round_number, qc_round_number):
        super().__init__(name, round_number, qc_round_number)
    
    def __eq__(self, __o: object) -> bool:
        if (isinstance(__o, Proposer)):
            return self.name == __o.name and 
            self.round_number == __o.round_number\
                and self.qc_round_number == __o.qc_round_number
        return False

class Handler(Node):
    def __init__(self, name, round_number, 
    qc_round_number, leader=None):
        super().__init__(name, round_number, qc_round_number)
        self.leader=leader

class Processer(Node):
    def __init__(self, name, round_number, 
    qc_round_number, leader=None):
        super().__init__(name, round_number, qc_round_number)
        self.leader=leader

class Voter(Node):
    def __init__(self, name, round_number, 
    qc_round_number, leader=None):
        super().__init__(name, round_number, qc_round_number)
        self.leader=leader

class MaliciousNode(Node):
    def __init__(self, name, round_number, 
    qc_round_number, attack_id, description):
        super().__init__(name, round_number, qc_round_number)
        self.attack_id = attack_id
        self.description = description
    def __eq__(self, __o: object) -> bool:
        if (isinstance(__o, MaliciousNode)):
            return self.name == __o.name 
            and self.round_number == __o.round_number\
                and self.qc_round_number == 
                __o.qc_round_number and self.attack_id == __o.attack_id \
                    and self.description == 
                    __o.description
        return False

class MaliciousButDueToLivenessOrAccidentNode(Node):
    def __init__(self, name, round_number, qc_round_number, description):
        super().__init__(name, round_number, qc_round_number)
        self.description = description
    def __eq__(self, __o: object) -> bool:
        if (isinstance(__o, MaliciousButDueToLivenessOrAccidentNode)):
            return self.name == __o.name 
            and self.round_number == __o.round_number\
                and self.qc_round_number == __o.qc_round_number and self.description == __o.description
        return False

def addProposer(new_proposer):
    proposer_list.append(new_proposer)

#https://www.tutorialspoint.com/How-to-sort-the-objects-in-a-list-in-Python#:~:text=How%20to%20sort%20the%20objects%20in%20a%20list,just%20pass%20in%20the%20reverse%20parameter%20as%20well.
def getObjKeyByRoundNumber(obj):
    return obj.round_number
    
def attackReporter(attack_id, reporter, round, qc_round):
    if attack_id == 1:
        if attack_1_reporter_to_roundqc.get(reporter, "default") == "default":
            #print("iii",reporter)
            attack_1_reporter_to_roundqc[reporter] = [[round, qc_round]]
        else:
           #print("reporter",reporter)
            attack_1_reporter_to_roundqc[reporter].append([round, qc_round])
    elif attack_id == 2:
        if attack_2_reporter_to_roundqc.get(reporter, "default") == "default":
            attack_2_reporter_to_roundqc[reporter] = [[round, qc_round]]
        else:
            attack_2_reporter_to_roundqc[reporter].append([round, qc_round])
    else:
        if attack_liveness_reporter_to_roundqc.get(reporter, "default") == "default":
            attack_liveness_reporter_to_roundqc[reporter] = [[round, qc_round]]
        else:
            attack_liveness_reporter_to_roundqc[reporter].append([round, qc_round])

# Util for adding safety attack proof for one malicious node
def detectSafetyAttack(name, round_number, qc_round_number, attack_id, description):
    proof_of_attempt_of_safety_attack.append(MaliciousNode(name=name,\
                                round_number=round_number, qc_round_number=qc_round_number, \
                                    attack_id=attack_id, description=description))
                                    
# Util for removing dup
def remove_duplicate_safety_attack():
    #print("DEDUP")
    if len(proof_of_attempt_of_safety_attack) == 0:
        return
    deduplicated_proof_of_attempt_of_safety_attack = [proof_of_attempt_of_safety_attack[0]]
    for i in range(1, len(proof_of_attempt_of_safety_attack)):
        if proof_of_attempt_of_safety_attack[i] != proof_of_attempt_of_safety_attack[i-1]:
            deduplicated_proof_of_attempt_of_safety_attack.append(proof_of_attempt_of_safety_attack[i])
    proof_of_attempt_of_safety_attack.clear()
    for i in deduplicated_proof_of_attempt_of_safety_attack:
        safetyattackRound.add(i.round_number)
        proof_of_attempt_of_safety_attack.append(i)
        
# Detect attack 2.2
def detectAttackTwoPtTwo():
    for i in range(1,len(proposer_list)):
        # FIX BUG 3: proposer_list[i].qc_round_number != proposer_list[i-1].qc_round_number WAS 
        # NOT INCLUDED AT FIRST SO SOME LIVENESS ATTACK ARE MISINTERPRETED AS 
        if proposer_list[i].name == proposer_list[i-1].name and \
            proposer_list[i].round_number == proposer_list[i-1].round_number and \
            proposer_list[i].qc_round_number != proposer_list[i-1].qc_round_number and \
            proposer_list[i].round_number not in safetyattackRound:
            detectSafetyAttack(proposer_list[i].name, proposer_list[i].round_number, \
                proposer_list[i].qc_round_number, 2, SAFETY_ATTACK_2_1)

def initDetector():
    detectAttackTwoPtTwo()

# Detect attack 3
def detectAttackThree():
    if len(proof_of_attempt_of_safety_attack) == 0:
        return
    attack_one_list = []
    # Gather all leaders doing attack 1
    for attack in proof_of_attempt_of_safety_attack:
        if attack.attack_id == 1:
            attack_one_list.append(attack)
            #print(attack.name,attack.round_number, attack.qc_round_number, attack.description )
    
    for attack in attack_one_list:
        for voter_index in range(0, len(voter_list)):
            #print(voter_list[voter_index].name, voter_list[voter_index].round_number, voter_list[voter_index].qc_round_number, voter_list[voter_index].leader)
            
            # Find 3.1 by comparing if voter shows voting message that matches the malicious leader's behavior in Attack 1
            if voter_list[voter_index].round_number == attack.round_number and \
                voter_list[voter_index].qc_round_number == attack.qc_round_number and\
                voter_list[voter_index].leader == attack.name and\
                    proof_of_attempt_of_safety_attack[-1] != MaliciousNode(name=voter_list[voter_index].name, round_number=voter_list[voter_index].round_number,\
                    qc_round_number=voter_list[voter_index].qc_round_number, attack_id=3, description=SAFETY_ATTACK_3_CORRECT_VOTE_REPORT):
                detectSafetyAttack(name=voter_list[voter_index].name, round_number=voter_list[voter_index].round_number,\
                    qc_round_number=voter_list[voter_index].qc_round_number, attack_id=3, description=SAFETY_ATTACK_3_CORRECT_VOTE_REPORT)
                #print(voter_list[voter_index].name, voter_list[voter_index].round_number, voter_list[voter_index].qc_round_number)

            # Find 3.2 by seeing whether voter did report the malicious leader for Attack 1 by comparing with attack_1_reporter_to_roundqc
            try:
                #print(attack_1_reporter_to_roundqc)
                if voter_list[voter_index].round_number == attack.round_number and \
                    voter_list[voter_index].qc_round_number != attack.qc_round_number and\
                    voter_list[voter_index+1].round_number != attack.round_number:
                    innocent = False
                    for attacker in proof_of_attempt_of_safety_attack:
                        if attacker.description == SAFETY_ATTACK_3_CORRECT_VOTE_REPORT and voter_list[voter_index].name ==attacker.name:
                            innocent = True
                            
                            break
                    if attack_1_reporter_to_roundqc.get(voter_list[voter_index].name, "default") != "default":
                        for i in attack_1_reporter_to_roundqc[voter_list[voter_index].name]:
                            if i[0] == attack.round_number and i[1] == attack.qc_round_number:
                                innocent = True
                                break

                    if innocent == False:
                        detectSafetyAttack(name=voter_list[voter_index].name, round_number=attack.round_number,\
                        qc_round_number=attack.qc_round_number, attack_id=3, description=SAFETY_ATTACK_3_NO_OR_WRONG_VOTE_REPORT)
                        
            except:
                if attack_1_reporter_to_roundqc.get(voter_list[voter_index].name, "default") != "default":
                    for i in attack_1_reporter_to_roundqc[voter_list[voter_index].name]:
                        if i[0] == attack.round_number and i[1] == attack.qc_round_number:
                            innocent = True
                            break

                if innocent == False:
                    detectSafetyAttack(name=voter_list[voter_index].name, round_number=voter_list[voter_index].round_number,\
                    qc_round_number=voter_list[voter_index].qc_round_number, attack_id=3, description=SAFETY_ATTACK_3_NO_OR_WRONG_VOTE_REPORT)
            

# Detect attack 4
def detectAttackFour():
    attack_two_pt_one_list = []
    # Gather all leaders doing attack 2.1
    for attack in proof_of_attempt_of_safety_attack:
        if attack.description == SAFETY_ATTACK_2_2:
            attack_two_pt_one_list.append(attack)
            #print(attack.name,attack.round_number, attack.qc_round_number, attack.description )
    for attack in attack_two_pt_one_list:
        for handler_index in range(0, len(handler_list)):
            #print("attack 4", handler.name, handler.round_number, handler.qc_round_number)
            #print("mali", attack.name, attack.round_number, attack.qc_round_number)
            # need to check leader too to avoid false positive like the 1 0, 1 0 examples

            # detect attack 4.1.1
            if handler_list[handler_index].round_number == attack.round_number and \
                handler_list[handler_index].qc_round_number == attack.qc_round_number and \
                handler_list[handler_index].leader == attack.name and\
                    proof_of_attempt_of_safety_attack[-1] != MaliciousNode(name=handler_list[handler_index].name, round_number=handler_list[handler_index].round_number,\
                    qc_round_number=handler_list[handler_index].qc_round_number, attack_id=4, description=SAFETY_ATTACK_4_2_CORRECT_VOTE_REPORT):
                detectSafetyAttack(name=handler_list[handler_index].name, round_number=handler_list[handler_index].round_number,\
                    qc_round_number=handler_list[handler_index].qc_round_number, attack_id=4, description=SAFETY_ATTACK_4_2_CORRECT_VOTE_REPORT)
                
            # detect attack 4.1.2
            try:
                #print(attack_2_reporter_to_roundqc)
                #print("handler", handler_list[handler_index].name, handler_list[handler_index].round_number, handler_list[handler_index].qc_round_number)
                # if this node doesn not report the bad leader in attack 4.1
                if handler_list[handler_index].name != handler_list[handler_index+1].name\
                and handler_list[handler_index].name not in list(attack_2_reporter_to_roundqc.keys()):
                    innocent = False
                    #print("handler", handler_list[handler_index].name, handler_list[handler_index].round_number, handler_list[handler_index].qc_round_number)
                    # check if already considered doing attack 4.1.1 and skip
                    for attacker in proof_of_attempt_of_safety_attack:
                        if attacker.description == SAFETY_ATTACK_4_2_CORRECT_VOTE_REPORT and handler_list[handler_index].name ==attacker.name:
                            innocent = True
                            break
                    
                    # check if didn't report or wrongly report
                    if attack_2_reporter_to_roundqc.get(handler_list[handler_index].name, "default") != "default":
                        for i in attack_2_reporter_to_roundqc[handler_list[handler_index].name]:
                            if i[0] == attack.round_number and i[1] == attack.qc_round_number:
                                innocent = True
                                break

                    if innocent == False:
                        detectSafetyAttack(name=handler_list[handler_index].name, round_number=attack.round_number,\
                        qc_round_number=attack.qc_round_number, attack_id=4, description=SAFETY_ATTACK_4_2_NO_OR_WRONG_VOTE_REPORT)
                        
            except: # if last name in handler_list
                if handler_list[handler_index].name not in list(attack_2_reporter_to_roundqc.keys()):
                    innocent = False
                    #print("handler", handler_list[handler_index].name, attack.round_number, attack.qc_round_number)
                    # check if already considered doing attack 4.1.1and skip
                    for attacker in proof_of_attempt_of_safety_attack:
                        if attacker.description == SAFETY_ATTACK_4_2_CORRECT_VOTE_REPORT and handler_list[handler_index].name ==attacker.name:
                            innocent = True
                            
                            break
                    
                    # check if didn't report or wrongly report
                    if attack_2_reporter_to_roundqc.get(handler_list[handler_index].name, "default") != "default":
                        for i in attack_2_reporter_to_roundqc[handler_list[handler_index].name]:
                            if i[0] == attack.round_number and i[1] == attack.qc_round_number:
                                innocent = True
                                break

                    if innocent == False:
                        detectSafetyAttack(name=handler_list[handler_index].name, round_number=attack.round_number,\
                        qc_round_number=attack.qc_round_number, attack_id=4, description=SAFETY_ATTACK_4_2_NO_OR_WRONG_VOTE_REPORT)   
    attack_two_pt_two_list = []

    # Gather all leaders doing attack 2.2
    for attack in proof_of_attempt_of_safety_attack:
        if attack.description == SAFETY_ATTACK_2_2:
            attack_two_pt_two_list.append(attack)
            #print(">>>",attack.name,attack.round_number, attack.qc_round_number, attack.description )
    for attack in attack_two_pt_two_list:
        for processer_index in range(0, len(processer_list)):
            # need to check leader too to avoid false positive like the 1 0, 1 0 examples
            # detect 4.2.1


            # FIX BUG 4: forgot to include processer_list[processer_index].name not in attack_2_reporter_to_roundqc.keys()
            # to release innocent reporter
            if processer_list[processer_index].round_number == attack.round_number and \
                processer_list[processer_index].qc_round_number == attack.qc_round_number and \
                processer_list[processer_index].leader == attack.name and\
                    proof_of_attempt_of_safety_attack[-1] != MaliciousNode(name=processer_list[processer_index].name, round_number=processer_list[processer_index].round_number,\
                    qc_round_number=processer_list[processer_index].qc_round_number, attack_id=4, description=SAFETY_ATTACK_4_1_CORRECT_VOTE_REPORT) and \
                        processer_list[processer_index].name not in attack_2_reporter_to_roundqc.keys():
                detectSafetyAttack(name=processer_list[processer_index].name, round_number=processer_list[processer_index].round_number,\
                    qc_round_number=processer_list[processer_index].qc_round_number, attack_id=4, description=SAFETY_ATTACK_4_1_CORRECT_VOTE_REPORT)
                
            # detect 4.2.2
            try:
                if processer_list[processer_index].name != processer_list[processer_index+1].name\
                and processer_list[processer_index].name not in list(attack_2_reporter_to_roundqc.keys()):
                    innocent = False
                    # check if already considered doing attack 4.2.1 for this proposal and skip
                    for attacker in proof_of_attempt_of_safety_attack:
                        if attacker.description == SAFETY_ATTACK_4_1_CORRECT_VOTE_REPORT and processer_list[processer_index].name ==attacker.name:
                            innocent = True
                            break
                    
                    # check if didn't report or wrongly report
                    if attack_2_reporter_to_roundqc.get(processer_list[processer_index].name, "default") != "default":
                        for i in attack_2_reporter_to_roundqc[processer_list[processer_index].name]:
                            if i[0] == attack.round_number and i[1] == attack.qc_round_number:
                                innocent = True
                                break

                    if innocent == False:
                        detectSafetyAttack(name=processer_list[processer_index].name, round_number=attack.round_number,\
                        qc_round_number=attack.qc_round_number, attack_id=4, description=SAFETY_ATTACK_4_1_NO_OR_WRONG_VOTE_REPORT)
            except:# last node
                if processer_list[processer_index].name not in list(attack_2_reporter_to_roundqc.keys()):
                    innocent = False
                    # check if already considered doing attack 4.2.1 for this proposal and skip
                    for attacker in proof_of_attempt_of_safety_attack:
                        if attacker.description == SAFETY_ATTACK_4_1_CORRECT_VOTE_REPORT and processer_list[processer_index].name ==attacker.name:
                            innocent = True
                            break
                    
                    # check if didn't report or wrongly report
                    if attack_2_reporter_to_roundqc.get(processer_list[processer_index].name, "default") != "default":
                        for i in attack_2_reporter_to_roundqc[processer_list[processer_index].name]:
                            if i[0] == attack.round_number and i[1] == attack.qc_round_number:
                                innocent = True
                                break

                    if innocent == False:
                        detectSafetyAttack(name=processer_list[processer_index].name, round_number=attack.round_number,\
                        qc_round_number=attack.qc_round_number, attack_id=4, description=SAFETY_ATTACK_4_1_NO_OR_WRONG_VOTE_REPORT)
                        
def main():
    start_time = time.time()
    parseLog()
    initDetector()
    '''for i in voter_list:
        print("voter", i.name, i.round_number, i.qc_round_number)
    for i in handler_list:
        print("handler", i.name, i.round_number, i.qc_round_number)'''
    detectAttackThree()
    detectAttackFour()
    
    proof_of_attempt_of_safety_attack.sort(key=lambda x: (x.name, x.round_number, x.qc_round_number, x.description))
    remove_duplicate_safety_attack()
    detectLivenessWhichIsActuallySafetyAttack()
    print("\n\nFinal Safety Attack")
    for i in proof_of_attempt_of_safety_attack:
        print(i.name, i.round_number, i.qc_round_number, i.description)
    
    elapsed_time = time.time() - start_time
    print("Time to detect malicious nodes: ", elapsed_time, "seconds")
\end{lstlisting}
\subsection{Eliminating some liveness attacks}
\label{appendix:eliminateLiveness}
\begin{lstlisting}[language=Python]
# Util for removing dup
def remove_duplicate_liveness_attack():
    #print("DEDUP")
    if len(proof_of_attempt_of_non_safety_attack) == 0:
        return
    deduplicated_proof_of_attempt_of_non_safety_attack = [proof_of_attempt_of_non_safety_attack[0]]
    for i in range(1, len(proof_of_attempt_of_non_safety_attack)):
        if proof_of_attempt_of_non_safety_attack[i] != proof_of_attempt_of_non_safety_attack[i-1]:
            deduplicated_proof_of_attempt_of_non_safety_attack.append(proof_of_attempt_of_non_safety_attack[i])
    proof_of_attempt_of_non_safety_attack.clear()
    for i in deduplicated_proof_of_attempt_of_non_safety_attack:
        proof_of_attempt_of_non_safety_attack.append(i)
        
# Just put liveness or Accidental stuff inside 
def detectLivenessOrAccident(name, round_number, qc_round_number, description):
    proof_of_attempt_of_non_safety_attack.append(MaliciousButDueToLivenessOrAccidentNode(name, round_number, qc_round_number, description ))


# FIX BUG 1: In 10_30 it will not be 100% precision because 1, Attack 1: issue: sometimes honest block will not receive block to vote, like 10_30's 14 that node 8, when the attacker is doing 
#arrack 1, the attacker sends 2 blocks. But this node 8 didn't receive the first honest block and didn't update self.last_voted_round,
#and when it sees the second malicious block, it will say pass the safety rule 1 unexpectedly, which should not passed, causing it to be
#not reporting malicious leader, thus false positive here on wronlg cathing node 8

# Fix is depends on storing all attempts of liveness attacks, and any Accidental message losses behavior
# Then compare with this list of safety attacker that any attacker wrongly caught as doing safety
# attacks 3 by not reporting malicious leaders will be considered innocent on safety attack if they 
# report and misconsidered as liveness
def detectLivenessWhichIsActuallySafetyAttack():
    innocent_voter = []
    for name, roundqc in attack_liveness_reporter_to_roundqc.items():
        for attacker in proof_of_attempt_of_safety_attack:
            for little_roundqc in roundqc:
                if name == attacker.name and little_roundqc[0] == attacker.round_number and \
                    little_roundqc[1] == attacker.qc_round_number:
                    innocent_voter.append(attacker)
    temp_proof_of_attempt_of_safety_attack = []
    for attack in proof_of_attempt_of_safety_attack:
        temp_proof_of_attempt_of_safety_attack.append(attack)
    proof_of_attempt_of_safety_attack.clear()
    for attack in temp_proof_of_attempt_of_safety_attack:
        innocent = False
        for voter in innocent_voter:
            if voter.name == attack.name and voter.round_number == attack.round_number and\
            voter.qc_round_number == attack.qc_round_number:
                innocent = True
                break
        if innocent == False:
            proof_of_attempt_of_safety_attack.append(attack)
\end{lstlisting}

\section{Source code for Tester}
\subsection{Tester}
\label{appendix:tester}
\begin{lstlisting}[language=Python]
# Not using pytest since correctness is what this project seeks for
# instead of strictly 100% passing all test cases
from doctest import testfile
from re import I
from bft_detector import run
import os
import sys

STDIN_FOLDER = 'logs/1_10_1ML_10_50/'
MALICIOUS_RANDOM_NODE_ID = [500, 600, 700]
HONEST_NODE_NAME_TO_IS_THERE_ATTACK = {}
MALICIOUS_LEADER_ROUND_OF_ATTACK = {10:0, 25:0}
file_index_to_malicious_nodes = {}
file_index_to_malicious_nodes_cheated = {}
file_index_to_all_lines = {}
TIME_LIMIT = 60
time = []
pubkey_to_attack_id = {}
pubkey_to_attack_id_cheated = {}

# This is a basic test
# test if detector work well without compilation error
# and can stdout the files of detection results
def test_stdout_files(file, fn):
    run(file, fn)
    return

# This is a basic test
# test if honest nodes are wrongly caught as malicious(false positive)
# return false positive nodes and Precision (SupposesMaliciousNodes/(WronglyCaughtHonestNodes+SupposesMaliciousNodes))
def test_all_detected_precision():
    print("\n\n-----------False Positive Test Start--------------\n\n")
    SupposesMaliciousNodes = 0
    WronglyCaughtHonestNodes = 0
    for k, _ in file_index_to_malicious_nodes.items():
        if len(file_index_to_malicious_nodes[k]) == len(file_index_to_malicious_nodes_cheated[k]):
            print("\nMatches numbers of unique malicious nodes")
            print("Detector's malicious nodes:", file_index_to_malicious_nodes[k], \
                "with numbers of ", len(file_index_to_malicious_nodes[k]))
            print("Actual malicious nodes:", file_index_to_malicious_nodes_cheated[k], \
                "with numbers of ", len(file_index_to_malicious_nodes_cheated[k]), "\n")
        elif len(file_index_to_malicious_nodes[k]) > len(file_index_to_malicious_nodes_cheated[k]):
            '''for malicious_node in file_index_to_malicious_nodes[k]:
                if HONEST_NODE_NAME_TO_IS_THERE_ATTACK[malicious_node] == False:
                    print("HONEST")
                    file_index_to_malicious_nodes_cheated[k].append(malicious_node)
            if len(file_index_to_malicious_nodes[k]) == len(file_index_to_malicious_nodes_cheated[k]):
                print("\nMatches numbers of unique malicious nodes")
                print("Detector's malicious nodes:", file_index_to_malicious_nodes[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes[k]))
                print("Actual malicious nodes:", file_index_to_malicious_nodes_cheated[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes_cheated[k]), "\n")
            elif len(file_index_to_malicious_nodes[k]) > len(file_index_to_malicious_nodes_cheated[k]):

                print("\nNOT Matches numbers of unique malicious nodes")
                print("Detector's malicious nodes:", file_index_to_malicious_nodes[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes[k]))
                print("Actual malicious nodes:", file_index_to_malicious_nodes_cheated[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes_cheated[k]), "\n")
                WronglyCaughtHonestNodes += len(file_index_to_malicious_nodes[k]) - len(file_index_to_malicious_nodes_cheated[k])'''
            print("\nNOT Matches numbers of unique malicious nodes")
            print("Detector's malicious nodes:", file_index_to_malicious_nodes[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes[k]))
            print("Actual malicious nodes:", file_index_to_malicious_nodes_cheated[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes_cheated[k]), "\n")
            WronglyCaughtHonestNodes += len(file_index_to_malicious_nodes[k]) - len(file_index_to_malicious_nodes_cheated[k])
        SupposesMaliciousNodes += len(file_index_to_malicious_nodes_cheated[k])
    precision = SupposesMaliciousNodes/(WronglyCaughtHonestNodes+SupposesMaliciousNodes)
    print("\n\n-----------Precision is", "{:.2%}".format(precision), "--------------\n\n")
    print("\n\n-----------False Positive Test End--------------\n\n")
    return precision
# This is a basic test
# test if malicious nodes are not detected
# return false negative nodes and Recall (SupposesMaliciousNodes/(IgnoredMaliciousNodes+SupposesMaliciousNodes))
def test_all_detected_recall():
    print("\n\n-----------False Negative Test Start--------------\n\n")
    SupposesMaliciousNodes = 0
    IgnoredMaliciousNodes = 0
    for k, _ in file_index_to_malicious_nodes.items():
        if len(file_index_to_malicious_nodes[k]) == len(file_index_to_malicious_nodes_cheated[k]):
            print("\nMatches numbers of unique malicious nodes")
            print("Detector's malicious nodes:", file_index_to_malicious_nodes[k], \
                "with numbers of ", len(file_index_to_malicious_nodes[k]))
            print("Actual malicious nodes:", file_index_to_malicious_nodes_cheated[k], \
                "with numbers of ", len(file_index_to_malicious_nodes_cheated[k]), "\n")
        # FIX BUG 5: When there's honest nodes but fail to send messages due to liveness or 
        # Accidental stuff, it is wrongly interpreted by the tester as malicious nodes ,and 
        # here need to eliminate them from tester's cheat list
        elif len(file_index_to_malicious_nodes[k]) < len(file_index_to_malicious_nodes_cheated[k]):
            for malicious_node in file_index_to_malicious_nodes_cheated[k]:
                try:
                    if HONEST_NODE_NAME_TO_IS_THERE_ATTACK[malicious_node] == False:
                        file_index_to_malicious_nodes[k].append(malicious_node)
                except:
                    continue
            if len(file_index_to_malicious_nodes[k]) == len(file_index_to_malicious_nodes_cheated[k]):
                print("\nMatches numbers of unique malicious nodes")
                print("Detector's malicious nodes:", file_index_to_malicious_nodes[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes[k]))
                print("Actual malicious nodes:", file_index_to_malicious_nodes_cheated[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes_cheated[k]), "\n")
            elif len(file_index_to_malicious_nodes[k]) < len(file_index_to_malicious_nodes_cheated[k]):

                print("\nNOT Matches numbers of unique malicious nodes")
                print("Detector's malicious nodes:", file_index_to_malicious_nodes[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes[k]))
                print("Actual malicious nodes:", file_index_to_malicious_nodes_cheated[k], \
                    "with numbers of ", len(file_index_to_malicious_nodes_cheated[k]), "\n")
                IgnoredMaliciousNodes += len(file_index_to_malicious_nodes_cheated[k]) - len(file_index_to_malicious_nodes[k])
        SupposesMaliciousNodes += len(file_index_to_malicious_nodes_cheated[k])
    recall = SupposesMaliciousNodes/(IgnoredMaliciousNodes+SupposesMaliciousNodes)
    print("\n\n-----------Recall is", "{:.2%}".format(recall), "--------------\n\n")
    print("\n\n-----------False Negative Test End--------------\n\n")
    return recall

# This is a basic test
# test is time in quasi-real time
def test_time():
    print("\n\n-----------Time Test Start--------------\n\n")
    for tm in time:
        if tm > TIME_LIMIT:
            print("\n\n-----------Time Test End--------------\n\n")
            return False
    print("\n\n-----------Time Test End--------------\n\n")
    return True

def gather_attack_category_by_attack_id():
    for k, v in file_index_to_malicious_nodes.items():
        for pubkey in v:
            for k_2, v_2 in file_index_to_all_lines.items():
                for line in v_2:
                    if line[1].strip() == pubkey and (line[0].strip() == '3' or line[0].strip() == '4'):
                        if pubkey_to_attack_id.get(pubkey, "default") == "default":
                            pubkey_to_attack_id[pubkey] = [int(line[0].strip())]
                        else:
                            pubkey_to_attack_id[pubkey].append(int(line[0].strip()))
    for k, v in pubkey_to_attack_id.items():
        pubkey_to_attack_id[k].sort()
    print(pubkey_to_attack_id)

def gather_attack_category_by_cheating():
    for k,v in pubkey_to_attack_id_cheated.items():
        pubkey_to_attack_id_cheated[k] = list(set(v))
    print(pubkey_to_attack_id_cheated)

# This is an advanced test
# test is each attack really belongs to its attack category, focusing on voter
# eg: the proof "3 Dn2i9Ipd91uJqz0C 10 0 This node is performing attack 3.1 that it votes for proposals in attack 1, and it is reporting CORRECT voting information"
# Test is the above pubkey Dn2i9Ipd91uJqz0C really performing Attack 3
# return correctness
def test_attack_category_voter():
    print("\n\n-----------Verify Voter does do its attack 3 or 4 Test Start--------------\n\n")
    gather_attack_category_by_attack_id()
    gather_attack_category_by_cheating()
    DetectorCorrectNumber = 0
    ActualCorrectNumber = 0
    # for cheat_list and detector_list there will only be [3, 4] or [4], or [3] or no key
    for k,cheat_list in pubkey_to_attack_id_cheated.items():
        ActualCorrectNumber += len(cheat_list)
        detector_list = []
        try:
            detector_list = list(set(pubkey_to_attack_id[k]))
        except:
            # If no key then wrong and continue
            continue
        # If length not same, then will either [3] vs [3,4] or [4] vs [3,4], One fault
        if len(cheat_list) != len(detector_list):
            print("Mismatch: cheat_list is", cheat_list, "from pubkey", k, "and detector_list is",detector_list )
            DetectorCorrectNumber += 1
            continue
        # Now length same and is 1 for both. If content not same, like [3] vs [4], One fault
        if cheat_list[0] != detector_list[0]:
            print("Mismatch: cheat_list is", cheat_list, "from pubkey", k, "and detector_list is",detector_list )
            continue
        # Below is matching and add the deserved number
        if len(cheat_list) == 1:
            DetectorCorrectNumber += 1
            continue
        if len(cheat_list) == 2:
            DetectorCorrectNumber += 2
            continue
    correctness = DetectorCorrectNumber/ActualCorrectNumber
    print("\n\n-----------Correctness is ", correctness, "--------------\n\n")
    print("\n\n-----------Verify Voter does do its attack 3 or 4 Test End--------------\n\n")
    return correctness


def gather_results_from_detection():
    # Gather test file index mapped to malicious nodes and all results of detection 
    for i in range(1, 21): 
        with open('tests/test' + str(i) + '.txt') as f:
            lines = f.readlines()
            
            for line_index in range(0, len(lines)):
                line = lines[line_index].split(' ')
                print(line)
                if line[0] != "Final" and line[0] != "Time":
                    if file_index_to_all_lines.get(i, "default") == "default":
                        file_index_to_all_lines[i] = [line]
                    else:
                        file_index_to_all_lines[i].append(line)
                    if file_index_to_malicious_nodes.get(i, "default") == "default":
                        file_index_to_malicious_nodes[i] = [line[1]]
                    else:
                        file_index_to_malicious_nodes[i].append(line[1])
                if line[0] == "Time":
                    time.append(float(line[6].strip()))
        if file_index_to_malicious_nodes.get(i, "default") == "default":
            file_index_to_malicious_nodes[i] = []
        else:
            file_index_to_malicious_nodes[i] = list(set(file_index_to_malicious_nodes[i]))

    print(file_index_to_malicious_nodes)

def gather_results_from_files_by_cheating():
    # Gather additional logs that should not be interpreted by the detector
    # due to the instinct that they are for testing
    for i in range(1, 21):
        file_path = STDIN_FOLDER + str(i) + '/'
        node_files = [f_name for f_name in os.listdir(file_path)\
        if f_name.startswith('node')]
        for file in node_files:
            is_there_attack = False
            with open(file_path+file) as f:
                lines = f.readlines()
                node_name = ''
                for index in range(0, len(lines)):
                    line_list = lines[index].split(' ')

                    if len(line_list) >= 7 and line_list[6] == 'successfully':
                        node_name = line_list[5]
                    # Get all malicious leaders:
                    if len(line_list) >= 12 and line_list[4] == 'Created' and line_list[5] == 'with':
                        for k,v in MALICIOUS_LEADER_ROUND_OF_ATTACK.items():
                            if k == int(line_list[8].strip()) and v == int(line_list[11].strip()):
                                if file_index_to_malicious_nodes_cheated.get(i, "default") == "default":
                                    file_index_to_malicious_nodes_cheated[i] = [node_name]
                                else:
                                    file_index_to_malicious_nodes_cheated[i].append(node_name)
                    # Get all malicious voters
                    if len(line_list) >= 11 and line_list[9] == 'nanos':
                        random = int(line_list[10].strip())
                        #print(random)
                        if random in MALICIOUS_RANDOM_NODE_ID:
                            if file_index_to_malicious_nodes_cheated.get(i, "default") == "default":
                                file_index_to_malicious_nodes_cheated[i] = [node_name]
                            else:
                                file_index_to_malicious_nodes_cheated[i].append(node_name)
                        else:
                            HONEST_NODE_NAME_TO_IS_THERE_ATTACK[node_name] = False
                    if len(line_list) >= 7 and line_list[4] == 'Attack' and line_list[5] == '1':
                        is_there_attack = True
                    if len(line_list) >= 7 and line_list[4] == 'Attack' and line_list[5] == '2':
                        is_there_attack = True
                    if len(line_list) >= 7 and line_list[4] == 'Attack' and line_list[5] == '3':
                        if pubkey_to_attack_id_cheated.get(node_name, "default") == "default":
                            pubkey_to_attack_id_cheated[node_name] = [3]
                        else:
                            pubkey_to_attack_id_cheated[node_name].append(3)
                        is_there_attack = True

                    if len(line_list) >= 7 and line_list[4] == 'Attack' and line_list[5] == '4':
                        if pubkey_to_attack_id_cheated.get(node_name, "default") == "default":
                            pubkey_to_attack_id_cheated[node_name] = [4]
                        else:
                            pubkey_to_attack_id_cheated[node_name].append(4)
                        is_there_attack = True
            HONEST_NODE_NAME_TO_IS_THERE_ATTACK[node_name] = is_there_attack
        if file_index_to_malicious_nodes_cheated.get(i, "default") == "default":
            file_index_to_malicious_nodes_cheated[i] = []
        else:
            file_index_to_malicious_nodes_cheated[i] = list(set(file_index_to_malicious_nodes_cheated[i]))
    print(file_index_to_malicious_nodes_cheated)
    print(HONEST_NODE_NAME_TO_IS_THERE_ATTACK)

def test_attack_category_leader():
   for k, v in file_index_to_malicious_nodes.items():
        for pubkey in v:
            for k_2, v_2 in file_index_to_all_lines.items():
                for line in v_2:
                    if line[1].strip() == pubkey and (line[0].strip() == '1' or line[0].strip() == '2'):
                        return True

def main():
    temp = sys.stdout
    for i in range(1, 21):
        test_stdout_files(STDIN_FOLDER+str(i)+'/', i)
    sys.stdout = temp
    gather_results_from_detection()
    gather_results_from_files_by_cheating()
    precision = test_all_detected_precision()
    recall = test_all_detected_recall()
    is_exceed_time_limit = test_time()
    
    correctness_voter = test_attack_category_voter()
    is_malicious_leader_existed = test_attack_category_leader()
    print("\n\n\n---------------------------BASIC TEST DONE---------------------------------------")
    print("\n\n\n---------------------------PRECISION IS ","{:.2%}".format(precision), "---------------------------------------")
    print("\n\n\n---------------------------RECALL IS ","{:.2%}".format(recall), "---------------------------------------")
    print("\n\n\n---------------------------IS RUN IN QUASI-REAL TIME?",is_exceed_time_limit,"---------------------------------------\n\n\n")
    print("\n\n\n---------------------------ADVANCED TEST DONE---------------------------------------")
    print("\n\n\n-------------------CORRECTNESS THAT MALICOUS VOTER'S ATTACK CATEGORY IS CORRECTLY IDENTIFIED IS ", is_malicious_leader_existed, "---------------------------------")
    print("\n\n\n-------------------CORRECTNESS THAT MALICOUS VOTER'S ATTACK CATEGORY IS CORRECTLY IDENTIFIED IS ","{:.2%}".format(correctness_voter), "---------------------------------")
if __name__=='__main__':
    main()
\end{lstlisting}
\subsection{Script}
\label{appendix:scripts}
\begin{lstlisting}[language=Python]
import os, os.path
import glob
import shutil
import subprocess

trial = 1
try:
    os.mkdir("logs/1_10_1ML_50_50")
except:
    pass
des_list = []
while trial <= 20:
    des_list.append(os.getcwd()+"/logs/1_10_1ML_50_50/"+str(trial))
    trial+=1
trial = 1
print (os.getcwd())
os.chdir("../hotstuff/benchmark")
print (os.getcwd())
while trial <= 20:
    os.system("fab local")
    shutil.copytree("logs", des_list[trial-1])
    trial += 1

\end{lstlisting}
\section{Log for individual node after adding additional logs (partial) [9]}
\label{appendix:partialLoggingInfo}
\begin{lstlisting}
[2022-07-24T11:00:01.440Z INFO  consensus::core] Committed B44 with QC 43
[2022-07-24T11:00:01.440Z INFO  consensus::core] Committed B44 -> PCEHLWk3opgzBNCai4wGAI6Pvv9ogILVP9COtXroxN8=
[2022-07-24T11:00:01.440Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B46 with round number 46 with QC 45 from leader 2mBeBxd4eIoZcEqp
[2022-07-24T11:00:01.440Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B46 with round number 46 with QC 45 from leader 2mBeBxd4eIoZcEqp
[2022-07-24T11:00:01.441Z INFO  mempool::batch_maker] Batch 104lTN24pKPL/NR7ifKANH0IkJCLW5rsnTei/4wstjw= contains sample tx 185
[2022-07-24T11:00:01.441Z INFO  mempool::batch_maker] Batch 104lTN24pKPL/NR7ifKANH0IkJCLW5rsnTei/4wstjw= contains 2560 B
[2022-07-24T11:00:01.448Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B47 with round number 47 with QC 46 from leader 4MrsC/icx7DQjcnc
[2022-07-24T11:00:01.449Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B47 with round number 47 with QC 46 from leader 4MrsC/icx7DQjcnc
[2022-07-24T11:00:01.449Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B47 with round number 47 with QC 46 from leader 4MrsC/icx7DQjcnc
[2022-07-24T11:00:01.450Z WARN  network::simple_sender] Failed to connect to 127.0.0.1:9009 (retry 0): Connection refused (os error 111)
[2022-07-24T11:00:01.486Z INFO  mempool::batch_maker] Batch xKs99k80gnRugv6pzrZ37I1O/cKKcup9MSeJo20fbNY= contains sample tx 186
[2022-07-24T11:00:01.486Z INFO  mempool::batch_maker] Batch xKs99k80gnRugv6pzrZ37I1O/cKKcup9MSeJo20fbNY= contains 2560 B
[2022-07-24T11:00:01.532Z INFO  mempool::batch_maker] Batch Hdwgnjz1bKBc06BIYl+g8NgSIpkqWeC3SSHpeciQiTc= contains sample tx 187
[2022-07-24T11:00:01.532Z INFO  mempool::batch_maker] Batch Hdwgnjz1bKBc06BIYl+g8NgSIpkqWeC3SSHpeciQiTc= contains 2560 B
[2022-07-24T11:00:01.589Z INFO  mempool::batch_maker] Batch kdEEUQXMNbGNegqtl3ZDF40+1uoeDp+zE2CgKDSHFQI= contains sample tx 188
[2022-07-24T11:00:01.589Z INFO  mempool::batch_maker] Batch kdEEUQXMNbGNegqtl3ZDF40+1uoeDp+zE2CgKDSHFQI= contains 2560 B
[2022-07-24T11:00:01.635Z INFO  mempool::batch_maker] Batch S3kvd14oaoaHxfnsAIgMwBQwoxPSNUV2B27gu+80Ezk= contains sample tx 189
[2022-07-24T11:00:01.635Z INFO  mempool::batch_maker] Batch S3kvd14oaoaHxfnsAIgMwBQwoxPSNUV2B27gu+80Ezk= contains 2560 B
[2022-07-24T11:00:01.681Z INFO  mempool::batch_maker] Batch WHC69lWl2T8yunYqDDseMjPveEQknHLkOdqBJWfQvCc= contains sample tx 190
[2022-07-24T11:00:01.681Z INFO  mempool::batch_maker] Batch WHC69lWl2T8yunYqDDseMjPveEQknHLkOdqBJWfQvCc= contains 2560 B
[2022-07-24T11:00:01.737Z INFO  mempool::batch_maker] Batch tJ98W9N/KlScZ5FAZ1ZYAVla5MvP76UG7X0oQC3GCs0= contains sample tx 191
[2022-07-24T11:00:01.737Z INFO  mempool::batch_maker] Batch tJ98W9N/KlScZ5FAZ1ZYAVla5MvP76UG7X0oQC3GCs0= contains 2560 B
[2022-07-24T11:00:01.783Z INFO  mempool::batch_maker] Batch Kdtc0XttEvnO8nms2+n07wr4rngNGnQ/9KiVjwMwuv4= contains sample tx 192
[2022-07-24T11:00:01.783Z INFO  mempool::batch_maker] Batch Kdtc0XttEvnO8nms2+n07wr4rngNGnQ/9KiVjwMwuv4= contains 2560 B
[2022-07-24T11:00:01.829Z INFO  mempool::batch_maker] Batch hL20sTryd8fxD3XDy/uMYtMC2B87uCLQ2kW/hnIehbg= contains sample tx 193
[2022-07-24T11:00:01.829Z INFO  mempool::batch_maker] Batch hL20sTryd8fxD3XDy/uMYtMC2B87uCLQ2kW/hnIehbg= contains 2560 B
[2022-07-24T11:00:01.885Z INFO  mempool::batch_maker] Batch 11xvOUTeN6ddbhdpVgE/de2w4q0He1Rtw5G9gIrLq7U= contains sample tx 194
[2022-07-24T11:00:01.885Z INFO  mempool::batch_maker] Batch 11xvOUTeN6ddbhdpVgE/de2w4q0He1Rtw5G9gIrLq7U= contains 2560 B
[2022-07-24T11:00:01.930Z INFO  mempool::batch_maker] Batch VYkqrnvxTaf5xhg1ViTqCB2ArKZ//2/uQ/fhxI7sMFg= contains sample tx 195
[2022-07-24T11:00:01.930Z INFO  mempool::batch_maker] Batch VYkqrnvxTaf5xhg1ViTqCB2ArKZ//2/uQ/fhxI7sMFg= contains 1536 B
[2022-07-24T11:00:01.941Z INFO  mempool::batch_maker] Batch aHennBYqNY2F0x6XVm9HX/9pnUTT1iMmLZFcsn+o4Vo= contains 1024 B
[2022-07-24T11:00:01.988Z INFO  mempool::batch_maker] Batch NsHtCCRe3RZBOIVW9/9bQn9A5xLTvA1F1ii04JE4Lfs= contains sample tx 196
[2022-07-24T11:00:01.988Z INFO  mempool::batch_maker] Batch NsHtCCRe3RZBOIVW9/9bQn9A5xLTvA1F1ii04JE4Lfs= contains 2560 B
[2022-07-24T11:00:02.033Z INFO  mempool::batch_maker] Batch bXj1oDZoz9IxdnQ3KD2dIaEViK1C4kNS5UlbeIBl0S4= contains sample tx 197
[2022-07-24T11:00:02.033Z INFO  mempool::batch_maker] Batch bXj1oDZoz9IxdnQ3KD2dIaEViK1C4kNS5UlbeIBl0S4= contains 2560 B
[2022-07-24T11:00:02.079Z INFO  mempool::batch_maker] Batch Gv+vkuWvgiR2wuwsTg6yhyxMM9gnUSCXeZn3It3W2cc= contains 512 B
[2022-07-24T11:00:02.090Z INFO  mempool::batch_maker] Batch b4LVSB8D3kPOpHiztSr+t9Z+sJpQr54Y86nVJ7Nbnag= contains sample tx 198
[2022-07-24T11:00:02.090Z INFO  mempool::batch_maker] Batch b4LVSB8D3kPOpHiztSr+t9Z+sJpQr54Y86nVJ7Nbnag= contains 2048 B
[2022-07-24T11:00:02.134Z INFO  mempool::batch_maker] Batch bOusc6ghWFDPjDSzi8GGq2LKT04aFuAGldPDNzZnmpo= contains sample tx 199
[2022-07-24T11:00:02.134Z INFO  mempool::batch_maker] Batch bOusc6ghWFDPjDSzi8GGq2LKT04aFuAGldPDNzZnmpo= contains 2560 B
[2022-07-24T11:00:02.179Z INFO  mempool::batch_maker] Batch 5Nx15krdlj22/IOdzfMYhdpZDcaCX0lR/2FXi82czhw= contains sample tx 200
[2022-07-24T11:00:02.179Z INFO  mempool::batch_maker] Batch 5Nx15krdlj22/IOdzfMYhdpZDcaCX0lR/2FXi82czhw= contains 2560 B
[2022-07-24T11:00:02.238Z INFO  mempool::batch_maker] Batch ZvGS89/swqr7Ybr4r5QPKvjghOk6MV97QK3Rl7BJ21s= contains sample tx 201
[2022-07-24T11:00:02.238Z INFO  mempool::batch_maker] Batch ZvGS89/swqr7Ybr4r5QPKvjghOk6MV97QK3Rl7BJ21s= contains 2560 B
[2022-07-24T11:00:02.286Z INFO  mempool::batch_maker] Batch qhFRM3ZGKIEhlF4bTwEOUDSr4NzwmX7RzDXgVAK3VRs= contains sample tx 202
[2022-07-24T11:00:02.286Z INFO  mempool::batch_maker] Batch qhFRM3ZGKIEhlF4bTwEOUDSr4NzwmX7RzDXgVAK3VRs= contains 2560 B
[2022-07-24T11:00:02.333Z INFO  mempool::batch_maker] Batch 4/ivfL9A6m2jixGH+loct8e+kC8Ul51DQU2QpqReVJA= contains sample tx 203
[2022-07-24T11:00:02.333Z INFO  mempool::batch_maker] Batch 4/ivfL9A6m2jixGH+loct8e+kC8Ul51DQU2QpqReVJA= contains 2560 B
[2022-07-24T11:00:02.380Z INFO  mempool::batch_maker] Batch l+lObXiW48bodDeDEsFvH+YYe1s86xWDrVtCsxFxEpY= contains sample tx 204
[2022-07-24T11:00:02.380Z INFO  mempool::batch_maker] Batch l+lObXiW48bodDeDEsFvH+YYe1s86xWDrVtCsxFxEpY= contains 2560 B
[2022-07-24T11:00:02.435Z INFO  mempool::batch_maker] Batch UmbWl4zYnollJYAgImJQ+LddNXZL4XEW/m8h2QpRAjc= contains sample tx 205
[2022-07-24T11:00:02.435Z INFO  mempool::batch_maker] Batch UmbWl4zYnollJYAgImJQ+LddNXZL4XEW/m8h2QpRAjc= contains 2560 B
[2022-07-24T11:00:02.450Z WARN  consensus::core] Timeout reached for round 47
[2022-07-24T11:00:02.462Z WARN  network::simple_sender] Failed to connect to 127.0.0.1:9009 (retry 0): Connection refused (os error 111)
[2022-07-24T11:00:02.483Z INFO  mempool::batch_maker] Batch xgioYkWFin82cVL7OXAKOkGHg5tulQRaKosiq0led9Y= contains sample tx 206
[2022-07-24T11:00:02.483Z INFO  mempool::batch_maker] Batch xgioYkWFin82cVL7OXAKOkGHg5tulQRaKosiq0led9Y= contains 2560 B
[2022-07-24T11:00:02.538Z INFO  mempool::batch_maker] Batch T11IfRWIrtT4+lsywCvcSnZdlMLHTgjNKcvqxk6h20c= contains sample tx 207
[2022-07-24T11:00:02.538Z INFO  mempool::batch_maker] Batch T11IfRWIrtT4+lsywCvcSnZdlMLHTgjNKcvqxk6h20c= contains 2560 B
[2022-07-24T11:00:02.582Z INFO  mempool::batch_maker] Batch BTkxVcCKuhzBAMF+bl8RjQXEMV50GvjYkFCCCwyvO+w= contains sample tx 208
[2022-07-24T11:00:02.582Z INFO  mempool::batch_maker] Batch BTkxVcCKuhzBAMF+bl8RjQXEMV50GvjYkFCCCwyvO+w= contains 2560 B
[2022-07-24T11:00:02.630Z INFO  mempool::batch_maker] Batch eTJ842A27ldddCwHX35uD/tI989WgKn1lhyuzYAC+Ug= contains sample tx 209
[2022-07-24T11:00:02.630Z INFO  mempool::batch_maker] Batch eTJ842A27ldddCwHX35uD/tI989WgKn1lhyuzYAC+Ug= contains 2560 B
[2022-07-24T11:00:02.687Z INFO  mempool::batch_maker] Batch aIOot86DCDYyIqorfPi/sXCHCN5j+Q3sHF8GXd7+CYY= contains sample tx 210
[2022-07-24T11:00:02.687Z INFO  mempool::batch_maker] Batch aIOot86DCDYyIqorfPi/sXCHCN5j+Q3sHF8GXd7+CYY= contains 2560 B
[2022-07-24T11:00:02.733Z INFO  mempool::batch_maker] Batch dydX9+AXs5oORXGOM8dHJrH6Ww9zwWnEsQCJM0uazbY= contains sample tx 211
[2022-07-24T11:00:02.733Z INFO  mempool::batch_maker] Batch dydX9+AXs5oORXGOM8dHJrH6Ww9zwWnEsQCJM0uazbY= contains 2560 B
[2022-07-24T11:00:03.040Z INFO  mempool::batch_maker] Batch ezUR3PAVnYuFgyu6HYED6XsATrOb5dSfh5LO5C9Ddjk= contains sample tx 212
[2022-07-24T11:00:03.040Z INFO  mempool::batch_maker] Batch ezUR3PAVnYuFgyu6HYED6XsATrOb5dSfh5LO5C9Ddjk= contains sample tx 213
[2022-07-24T11:00:03.040Z INFO  mempool::batch_maker] Batch ezUR3PAVnYuFgyu6HYED6XsATrOb5dSfh5LO5C9Ddjk= contains sample tx 214
[2022-07-24T11:00:03.040Z INFO  mempool::batch_maker] Batch ezUR3PAVnYuFgyu6HYED6XsATrOb5dSfh5LO5C9Ddjk= contains sample tx 215
[2022-07-24T11:00:03.040Z INFO  mempool::batch_maker] Batch ezUR3PAVnYuFgyu6HYED6XsATrOb5dSfh5LO5C9Ddjk= contains sample tx 216
[2022-07-24T11:00:03.040Z INFO  mempool::batch_maker] Batch ezUR3PAVnYuFgyu6HYED6XsATrOb5dSfh5LO5C9Ddjk= contains sample tx 217
[2022-07-24T11:00:03.040Z INFO  mempool::batch_maker] Batch ezUR3PAVnYuFgyu6HYED6XsATrOb5dSfh5LO5C9Ddjk= contains 15360 B
[2022-07-24T11:00:03.085Z INFO  mempool::batch_maker] Batch +wcsrDegt1QJZSfDNXIno3DRkXmLlLxpb5v9lbPVHk4= contains sample tx 218
[2022-07-24T11:00:03.085Z INFO  mempool::batch_maker] Batch +wcsrDegt1QJZSfDNXIno3DRkXmLlLxpb5v9lbPVHk4= contains 2560 B
[2022-07-24T11:00:03.398Z INFO  mempool::batch_maker] Batch qmj/ljJ+kMGNlQ2hKfj9bRoEcpljtRP8zM46fXGeXU0= contains sample tx 219
[2022-07-24T11:00:03.398Z INFO  mempool::batch_maker] Batch qmj/ljJ+kMGNlQ2hKfj9bRoEcpljtRP8zM46fXGeXU0= contains sample tx 220
[2022-07-24T11:00:03.398Z INFO  mempool::batch_maker] Batch qmj/ljJ+kMGNlQ2hKfj9bRoEcpljtRP8zM46fXGeXU0= contains sample tx 221
[2022-07-24T11:00:03.398Z INFO  mempool::batch_maker] Batch qmj/ljJ+kMGNlQ2hKfj9bRoEcpljtRP8zM46fXGeXU0= contains sample tx 222
[2022-07-24T11:00:03.398Z INFO  mempool::batch_maker] Batch qmj/ljJ+kMGNlQ2hKfj9bRoEcpljtRP8zM46fXGeXU0= contains sample tx 223
[2022-07-24T11:00:03.398Z INFO  mempool::batch_maker] Batch qmj/ljJ+kMGNlQ2hKfj9bRoEcpljtRP8zM46fXGeXU0= contains 12800 B
[2022-07-24T11:00:03.409Z INFO  mempool::batch_maker] Batch KQ2WSUoY9ML9iMKAWJR5nKFPwD28RogTPQ/CJtNIsgA= contains sample tx 224
[2022-07-24T11:00:03.409Z INFO  mempool::batch_maker] Batch KQ2WSUoY9ML9iMKAWJR5nKFPwD28RogTPQ/CJtNIsgA= contains 2560 B
[2022-07-24T11:00:03.449Z INFO  mempool::batch_maker] Batch 6qUFku9DESg06S39XXaVKyVK/AATm+UufWJN7Uhh06c= contains sample tx 225
[2022-07-24T11:00:03.449Z INFO  mempool::batch_maker] Batch 6qUFku9DESg06S39XXaVKyVK/AATm+UufWJN7Uhh06c= contains 512 B
[2022-07-24T11:00:03.460Z INFO  mempool::batch_maker] Batch 2cGWlleCb0QGoHDgC0ufIbfyMNp8Q7iPZurDjHXHpUA= contains 2048 B
[2022-07-24T11:00:03.488Z WARN  consensus::core] Timeout reached for round 48
[2022-07-24T11:00:03.494Z WARN  network::simple_sender] Failed to connect to 127.0.0.1:9009 (retry 0): Connection refused (os error 111)
[2022-07-24T11:00:03.499Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.503Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.503Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.505Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.507Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.507Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.508Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.509Z INFO  mempool::batch_maker] Batch yyi/rBBEk3phogZQ+BuJ23sgXSvBRLeHqWw7jt/OnrE= contains sample tx 226
[2022-07-24T11:00:03.509Z INFO  mempool::batch_maker] Batch yyi/rBBEk3phogZQ+BuJ23sgXSvBRLeHqWw7jt/OnrE= contains 2560 B
[2022-07-24T11:00:03.510Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.510Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.523Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.525Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.525Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.525Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.528Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.528Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.529Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B50 with round number 50 with QC 49 from leader F0vrBB1wpjYm++Ww
[2022-07-24T11:00:03.530Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B50 with round number 50 with QC 49 from leader F0vrBB1wpjYm++Ww
[2022-07-24T11:00:03.530Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B50 with round number 50 with QC 49 from leader F0vrBB1wpjYm++Ww
[2022-07-24T11:00:03.532Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B50 with round number 50 with QC 0 from leader F0vrBB1wpjYm++Ww
[2022-07-24T11:00:03.533Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B50 with round number 50 with QC 0 from leader F0vrBB1wpjYm++Ww
[2022-07-24T11:00:03.533Z INFO  consensus::core] Attack 1 potentially detected!
[2022-07-24T11:00:03.533Z INFO  consensus::core] But needs detector to further check is it really Attack 1
[2022-07-24T11:00:03.533Z INFO  consensus::core] Is Safety Rule 1 satisfied? false
[2022-07-24T11:00:03.533Z INFO  consensus::core] Is Safety Rule 2 satisfied? false
[2022-07-24T11:00:03.533Z INFO  consensus::core] Proposal's Leader F0vrBB1wpjYm++Ww and round 50 and curr round 50 and QC round 0
[2022-07-24T11:00:03.533Z INFO  consensus::core] I am voter Z9rCyxwrcKmvy1Em with nanos 300
[2022-07-24T11:00:03.533Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.535Z INFO  consensus::core] I'm processor Z9rCyxwrcKmvy1Em processing for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.535Z INFO  consensus::core] I'm voter Z9rCyxwrcKmvy1Em voting for block B49 with round number 49 with QC 46 from leader /OAzoK7zUiIGBTDm
[2022-07-24T11:00:03.536Z INFO  mempool::batch_maker] Batch Ovta4c99cy2orBimUWAatOumcjhyH/KL7A7drD27Xgk= contains sample tx 227
[2022-07-24T11:00:03.536Z INFO  mempool::batch_maker] Batch Ovta4c99cy2orBimUWAatOumcjhyH/KL7A7drD27Xgk= contains 2560 B
[2022-07-24T11:00:03.536Z INFO  consensus::core] I'm handler Z9rCyxwrcKmvy1Em handling for block B51 with round number 51 with QC 50 from leader UQ6BkD30zAClYohh
[2022-07-24T11:00:03.538Z INFO  consensus::core] Committed B46 with QC 45
[2022-07-24T11:00:03.538Z INFO  consensus::core] Committed B46 -> FVvXo0b6D9LexOfXLBip6DNMqwycIRp7XAmN6rck5yA=
[2022-07-24T11:00:03.538Z INFO  consensus::core] Committed B46 -> +bSWtUxuTWNA/c+lTfX75FPH+3fZnCJ+K8lWbHgINs4=
[2022-07-24T11:00:03.538Z INFO  consensus::core] Committed B46 -> 8IFwoSBc8IvOdCUnA6jr4jAIZ4OSh6mF1pIRSc4ZwzY=
[2022-07-24T11:00:03.538Z INFO  consensus::core] Committed B46 -> bl2e1/ZcSowdO9/zJJBoKHFu/uNrbic0/Tnxq0g4QZY=
[2022-07-24T11:00:03.538Z INFO  consensus::core] Committed B46 -> GSKHkQsqaGKOHf1IT22NWlknkPdRFCGxsD72xoCAQ+8=
[2022-07-24T11:00:03.538Z INFO  consensus::core] Committed B46 -> 31VES+u78WsG26gDOu75ZGkl1+7kggB2UcXKhxnmU3o=
.............................................
.............................................
\end{lstlisting}
\section{Tables of results for each set of logs}
\label{appendix:results}
\begin{figure}[h]
\hspace*{-4cm}
  \includegraphics[scale=0.65]{f23.PNG}
\end{figure}\\\\


\end{document}
